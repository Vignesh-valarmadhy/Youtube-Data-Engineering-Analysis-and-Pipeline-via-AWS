{"Event":"SparkListenerLogStart","Spark Version":"3.5.2-amzn-1"}
{"Event":"SparkListenerResourceProfileAdded","Resource Profile Id":0,"Executor Resource Requests":{"executorType":{"Resource Name":"executorType","Amount":1,"Discovery Script":"","Vendor":""},"cores":{"Resource Name":"cores","Amount":4,"Discovery Script":"","Vendor":""},"memory":{"Resource Name":"memory","Amount":10240,"Discovery Script":"","Vendor":""},"offHeap":{"Resource Name":"offHeap","Amount":0,"Discovery Script":"","Vendor":""}},"Task Resource Requests":{"cpus":{"Resource Name":"cpus","Amount":1.0}}}
{"Event":"SparkListenerResourceProfileAdded","Resource Profile Id":1,"Executor Resource Requests":{"executorType":{"Resource Name":"executorType","Amount":1,"Discovery Script":"","Vendor":""},"cores":{"Resource Name":"cores","Amount":4,"Discovery Script":"","Vendor":""},"memory":{"Resource Name":"memory","Amount":10240,"Discovery Script":"","Vendor":""},"offHeap":{"Resource Name":"offHeap","Amount":0,"Discovery Script":"","Vendor":""}},"Task Resource Requests":{"cpus":{"Resource Name":"cpus","Amount":1.0}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"172.39.121.5","Port":33385},"Maximum Memory":6253707264,"Timestamp":1736633168720,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-17-amazon-corretto.x86_64","Java Version":"17.0.13 (Amazon.com Inc.)","Scala Version":"version 2.12.18"},"Spark Properties":{"spark.pyspark.python":"/usr/bin/python3.11","spark.glue.enable-observability-metrics":"true","spark.app.initial.archive.urls":"spark://172.39.121.5:46795/files/glue-job-286077850716913077_glue_venv.zip#python_environment","spark.dynamicAllocation.shuffleTracking.enabled":"true","spark.glue.additionalParams.ADDITIONAL_GLUE_JDK_OPTS":"-Xmx10g -XX:+UseG1GC -XX:MaxHeapFreeRatio=70 -XX:InitiatingHeapOccupancyPercent=45","spark.sql.parquet.fs.optimized.committer.optimization-enabled":"true","spark.hadoop.hive.metastore.client.factory.class":"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory","spark.metrics.conf.*.sink.GlueCloudwatch.jobRunId":"jr_4a19f832628913910d9c544e5b10d7c2f8b45f2669b5ee4537c6d875d1769971","spark.executor.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseParallelGC -XX:InitiatingHeapOccupancyPercent=70 -XX:OnOutOfMemoryError='kill -9 %p' -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseParallelGC -XX:InitiatingHeapOccupancyPercent=70 -XX:OnOutOfMemoryError='kill -9 %p'","spark.driver.host":"172.39.121.5","spark.serializer.objectStreamReset":"100","spark.history.fs.logDirectory":"file:///var/log/spark/apps","spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version.emr_internal_use_only.EmrFileSystem":"2","spark.hadoop.mapreduce.output.fs.optimized.committer.enabled":"true","spark.eventLog.enabled":"true","spark.glue.additionalParams.GLUE_LIBS_TEMP_DIR_PATH":"/tmp/glue-job-286077850716913077/","spark.archives":"/tmp/glue-job-286077850716913077_glue_venv.zip#python_environment","spark.hadoop.lakeformation.credentials.url":"http://localhost:9998/lakeformationcredentials","spark.hadoop.fs.s3.impl":"com.amazon.ws.emr.hadoop.fs.EmrFileSystem","spark.hadoop.fs.s3a.committer.name":"magicv2","spark.glue.JOB_RUN_ID":"jr_4a19f832628913910d9c544e5b10d7c2f8b45f2669b5ee4537c6d875d1769971","spark.metrics.conf.*.source.glue.verticalScaling.class":"org.apache.spark.metrics.source.VerticalScalingMetricsSource","spark.metrics.conf.driver.source.throughput.class":"org.apache.spark.metrics.source.ThroughputMetricsSource","spark.driver.port":"46795","spark.shuffle.service.enabled":"false","spark.emr-serverless.client.create.batch.size":"100","spark.extraListeners":"com.amazonaws.services.glueexceptionanalysis.GlueExceptionAnalysisListener","spark.rdd.compress":"True","spark.driver.extraLibraryPath":"/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native","spark.metrics.conf.*.sink.GlueCloudwatch.proxyHost":"null","spark.glue.enable-job-insights":"true","spark.glue.USE_PROXY":"false","spark.ui.custom.executor.log.url":"/logs/{{CONTAINER_ID}}/{{FILE_NAME}}.gz","spark.metrics.conf.*.source.jvm.class":"org.apache.spark.metrics.source.JvmSource","spark.executorEnv.PYTHONPATH":"python_environment","spark.jars":"/tmp/glue-job-286077850716913077/jars/pdhdHP-AwsGlueMLLibs.jar,/tmp/glue-job-286077850716913077/jars/t2hVEI-aws-glue-di-package-5.0.299.jar","spark.hadoop.fs.defaultFS":"file:///","spark.metrics.conf.driver.source.glue.jobPerformance.class":"org.apache.spark.metrics.source.PerformanceMetricsSource","spark.stage.attempt.ignoreOnDecommissionFetchFailure":"true","spark.ui.enabled":"false","spark.app.name":"nativespark-de-on-youtube-parquet-analystics-jr_4a19f832628913910d9c544e5b10d7c2f8b45f2669b5ee4537c6d875d1769971","spark.metrics.conf.driver.source.glue.resourceUtilization.class":"org.apache.spark.metrics.source.ResourceUtilizationMetricsSource","spark.hadoop.fs.s3a.aws.credentials.provider":"software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider","spark.network.timeout":"600","spark.glue.etl-enable-container-telemetry-collection":"false","spark.glue.additionalParams.PROXY_DISABLED":"false","spark.metrics.conf.*.sink.GlueCloudwatch.proxyPort":"-1","spark.hadoop.fs.s3.buffer.dir":"/tmp/hadoop/s3","spark.scheduler.mode":"FIFO","spark.driver.memory":"10g","spark.executor.instances":"9","spark.glue.GLUE_VERSION":"5.0","spark.files.fetchFailure.unRegisterOutputOnHost":"true","spark.glue.GLUE_TASK_GROUP_ID":"tg-033d0234c9127fc4061374744825662bc79d44f7","spark.hadoop.fs.s3bfs.impl":"org.apache.hadoop.fs.s3.S3FileSystem","spark.driver.bindAddress":"172.39.121.5","spark.default.parallelism":"36","spark.glue.glue-libs-temp-dir-path":"/tmp/glue-job-286077850716913077","spark.dynamicAllocation.maxExecutors":"9","spark.executor.defaultJavaOptions":"-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+UseParallelGC -XX:InitiatingHeapOccupancyPercent=70 -XX:OnOutOfMemoryError='kill -9 %p'","spark.glue.additionalParams.USER_JARS_FIRST":"false","spark.metrics.conf.*.source.system.class":"org.apache.spark.metrics.source.SystemMetricsSource","spark.resourceManager.cleanupExpiredHost":"true","spark.app.startTime":"1736633163833","spark.executor.id":"driver","spark.sql.emr.internal.extensions":"com.amazonaws.emr.spark.EmrSparkSessionExtensions","spark.glueJobInsights.enabled":"true","spark.glue.GLUE_COMMAND_CRITERIA":"glueetl","spark.driver.cores":"4","spark.submit.customResourceManager.submit.class":"org.apache.spark.deploy.emrserverless.submit.EmrServerlessClientApplication","spark.driver.extraJavaOptions":"-Djava.net.preferIPv6Addresses=false -XX:OnOutOfMemoryError='kill -9 %p' -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false -XX:OnOutOfMemoryError='kill -9 %p'","spark.emr-serverless.client.release.batch.size":"100","spark.hadoop.fs.s3.getObject.initialSocketTimeoutMilliseconds":"2000","spark.hadoop.fs.s3a.committer.magic.track.commits.in.memory.enabled":"true","spark.app.initial.jar.urls":"spark://172.39.121.5:46795/jars/pdhdHP-AwsGlueMLLibs.jar,spark://172.39.121.5:46795/jars/t2hVEI-aws-glue-di-package-5.0.299.jar","spark.submit.deployMode":"client","spark.metrics.conf.*.sink.GlueCloudwatch.accountId":"825765421264","spark.cloudwatch.logging.conf.jobRunId":"com.amazonaws.services.glue.launch.helpers.SparkPropsManager@580fd26b.LOGGING_JOB_RUN_ID","spark.glue.additionalParams.ADDITIONAL_CLASSPATH":"*********(redacted)","spark.master":"custom:jes","spark.glue.glue-python-libs-dir":"/tmp/glue-job-286077850716913077/python","spark.metrics.conf.driver.source.aggregate.class":"org.apache.spark.metrics.source.AggregateMetricsSource","spark.glue.glue-jars-dir":"/tmp/glue-job-286077850716913077/jars","spark.sql.parquet.output.committer.class":"com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter","spark.hadoop.fs.s3a.committer.magic.enabled":"true","spark.hadoop.fs.s3n.impl":"com.amazon.ws.emr.hadoop.fs.EmrFileSystem","spark.driver.defaultJavaOptions":"-XX:OnOutOfMemoryError='kill -9 %p'","spark.metrics.conf.driver.source.glue.jobPerformance.skewnessFactor":"5","spark.authenticate":"true","spark.metrics.conf.*.sink.GlueCloudwatch.jobName":"de-on-youtube-parquet-analystics","spark.authenticate.secret":"*********(redacted)","spark.blacklist.decommissioning.timeout":"1h","spark.executor.extraLibraryPath":"/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native","spark.sql.hive.metastore.sharedPrefixes":"software.amazon.awssdk.services.dynamodb","spark.script.location":"s3://aws-glue-assets-825765421264-us-east-1/scripts/de-on-youtube-par.py","spark.executor.memory":"10g","spark.driver.extraClassPath":"/usr/lib/livy/rsc-jars/*:/usr/lib/livy/repl_2.12-jars/*:/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/goodies/lib/emr-serverless-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/docker/usr/lib/hadoop-lzo/lib/*:/docker/usr/lib/hadoop/hadoop-aws.jar:/docker/usr/share/aws/aws-java-sdk/*:/docker/usr/share/aws/emr/emrfs/conf:/docker/usr/share/aws/emr/emrfs/lib/*:/docker/usr/share/aws/emr/emrfs/auxlib/*:/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/docker/usr/share/aws/emr/security/conf:/docker/usr/share/aws/emr/security/lib/*:/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/usr/share/aws/redshift/jdbc/RedshiftJDBC.jar:/usr/share/aws/redshift/spark-redshift/lib/*:/usr/share/aws/iceberg/lib/iceberg-emr-common.jar:/usr/share/aws/iceberg/lib/iceberg-spark3-runtime.jar","spark.eventLog.dir":"file:///var/log/spark/apps","spark.dynamicAllocation.enabled":"false","spark.executor.extraClassPath":"/usr/lib/hadoop-lzo/lib/*:/usr/lib/hadoop/hadoop-aws.jar:/usr/share/aws/aws-java-sdk/*:/usr/share/aws/emr/emrfs/conf:/usr/share/aws/emr/emrfs/lib/*:/usr/share/aws/emr/emrfs/auxlib/*:/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/usr/share/aws/emr/goodies/lib/emr-serverless-spark-goodies.jar:/usr/share/aws/emr/security/conf:/usr/share/aws/emr/security/lib/*:/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/docker/usr/lib/hadoop-lzo/lib/*:/docker/usr/lib/hadoop/hadoop-aws.jar:/docker/usr/share/aws/aws-java-sdk/*:/docker/usr/share/aws/emr/emrfs/conf:/docker/usr/share/aws/emr/emrfs/lib/*:/docker/usr/share/aws/emr/emrfs/auxlib/*:/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar:/docker/usr/share/aws/emr/security/conf:/docker/usr/share/aws/emr/security/lib/*:/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar:/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar:/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar:/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar:/usr/share/aws/redshift/jdbc/RedshiftJDBC.jar:/usr/share/aws/redshift/spark-redshift/lib/*:/usr/share/aws/iceberg/lib/iceberg-emr-common.jar:/usr/share/aws/iceberg/lib/iceberg-spark3-runtime.jar","spark.sql.catalogImplementation":"hive","spark.executor.cores":"4","spark.history.ui.port":"18080","spark.metrics.conf.*.source.s3.class":"org.apache.spark.metrics.source.S3FileSystemSource","spark.hadoop.fs.s3.customAWSCredentialsProvider":"com.amazonaws.auth.DefaultAWSCredentialsProviderChain","spark.glue.JOB_NAME":"de-on-youtube-parquet-analystics","spark.hadoop.fs.AbstractFileSystem.s3.impl":"org.apache.hadoop.fs.s3.EMRFSDelegate","spark.metrics.conf.*.sink.GlueCloudwatch.namespace":"Glue","spark.dynamicAllocation.minExecutors":"1","spark.dynamicAllocation.initialExecutors":"3","spark.files.useFetchCache":"false","spark.blacklist.decommissioning.enabled":"true","spark.metrics.conf.*.sink.GlueCloudwatch.glueVersion":"5.0","spark.decommissioning.timeout.threshold":"20","spark.metrics.conf.*.sink.GlueCloudwatch.class":"org.apache.spark.metrics.sink.GlueCloudwatchSink","spark.sql.extensions":"com.amazonaws.services.glue.spark.extensions.SparkGlueBookmarkExtension","spark.emr-serverless.client.describe.batch.size":"100","spark.metrics.conf.*.sink.GlueCloudwatch.legacyMetrics":"true","spark.hadoop.mapreduce.fileoutputcommitter.cleanup-failures.ignored.emr_internal_use_only.EmrFileSystem":"true","spark.glue.additionalParams.PROXY_DISABLED_V2":"false","spark.app.id":"spark-application-1736633168473","spark.glue.jobLanguage":"python","spark.sql.shuffle.partitions":"36"},"Hadoop Properties":{"hadoop.service.shutdown.timeout":"30s","yarn.resourcemanager.amlauncher.thread-count":"50","yarn.sharedcache.enabled":"false","fs.s3a.connection.maximum":"500","yarn.nodemanager.numa-awareness.numactl.cmd":"/usr/bin/numactl","fs.viewfs.overload.scheme.target.o3fs.impl":"org.apache.hadoop.fs.ozone.OzoneFileSystem","fs.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms":"1000","yarn.timeline-service.timeline-client.number-of-async-entities-to-merge":"10","hadoop.security.kms.client.timeout":"60","hadoop.http.authentication.kerberos.principal":"HTTP/_HOST@LOCALHOST","mapreduce.jobhistory.loadedjob.tasks.max":"-1","yarn.resourcemanager.application-tag-based-placement.enable":"false","mapreduce.framework.name":"yarn","yarn.sharedcache.uploader.server.thread-count":"50","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds.min":"3600","yarn.nodemanager.linux-container-executor.nonsecure-mode.user-pattern":"^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$","tfile.fs.output.buffer.size":"262144","yarn.app.mapreduce.am.job.task.listener.thread-count":"60","yarn.nodemanager.node-attributes.resync-interval-ms":"120000","yarn.nodemanager.container-log-monitor.interval-ms":"60000","yarn.resourcemanager.decommissioning-nodes-watcher.wait-for-shuffle-data":"false","hadoop.security.groups.cache.background.reload.threads":"3","yarn.resourcemanager.webapp.cross-origin.enabled":"false","fs.AbstractFileSystem.ftp.impl":"org.apache.hadoop.fs.ftp.FtpFs","fs.viewfs.overload.scheme.target.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","hadoop.registry.secure":"false","hadoop.shell.safely.delete.limit.num.files":"100","fs.s3.buffer.dir":"/tmp/hadoop/s3","mapreduce.job.acl-view-job":" ","fs.s3a.retry.limit":"7","mapreduce.jobhistory.loadedjobs.cache.size":"5","yarn.timeline-service.client.create-entity-file-path":"false","mapreduce.outputcommitter.factory.scheme.abfs":"org.apache.hadoop.fs.azurebfs.commit.AzureManifestCommitterFactory","yarn.router.interceptor.user-thread-pool.allow-core-thread-time-out":"false","yarn.log-aggregation.enable-local-cleanup":"true","fs.viewfs.overload.scheme.target.s3a.impl":"org.apache.hadoop.fs.s3a.S3AFileSystem","dfs.namenode.handler.count":"64","yarn.nodemanager.amrmproxy.enabled":"false","yarn.timeline-service.entity-group-fs-store.with-user-dir":"false","mapreduce.shuffle.pathcache.expire-after-access-minutes":"5","mapreduce.input.fileinputformat.split.minsize":"0","yarn.resourcemanager.container.liveness-monitor.interval-ms":"600000","dfs.namenode.replication.max-streams":"20","yarn.resourcemanager.client.thread-count":"50","io.seqfile.compress.blocksize":"1000000","mapreduce.tasktracker.http.threads":"60","yarn.nodemanager.runtime.linux.docker.allowed-container-runtimes":"runc","fs.viewfs.overload.scheme.target.http.impl":"org.apache.hadoop.fs.http.HttpFileSystem","fs.s3.getObject.initialSocketTimeoutMilliseconds":"2000","yarn.nodemanager.least-load-policy-selector.fail-on-error":"true","yarn.resourcemanager.nodemanagers.heartbeat-interval-slowdown-factor":"1.0","yarn.sharedcache.checksum.algo.impl":"org.apache.hadoop.yarn.sharedcache.ChecksumSHA256Impl","yarn.router.submit.interval.time":"10ms","yarn.nodemanager.amrmproxy.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.nodemanager.amrmproxy.DefaultRequestInterceptor","dfs.datanode.data.dir":"file:///mnt/hdfs","dfs.replication":"2","yarn.timeline-service.entity-group-fs-store.leveldb-cache-read-cache-size":"10485760","mapreduce.reduce.shuffle.fetch.retry.interval-ms":"1000","mapreduce.task.profile.maps":"0-2","yarn.scheduler.include-port-in-node-name":"false","yarn.resourcemanager.scheduler.autocorrect.container.allocation":"false","yarn.nodemanager.admin-env":"MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX","yarn.resourcemanager.node-removal-untracked.timeout-ms":"120000","yarn.router.interceptor.user-thread-pool.keep-alive-time":"30s","mapreduce.am.max-attempts":"2","hadoop.security.kms.client.failover.sleep.base.millis":"100","fs.s3a.connection.ttl":"5m","yarn.router.asc-interceptor-max-size":"1MB","mapreduce.jobhistory.webapp.https.address":"0.0.0.0:19890","yarn.node-labels.fs-store.impl.class":"org.apache.hadoop.yarn.nodelabels.FileSystemNodeLabelsStore","yarn.nodemanager.collector-service.address":"${yarn.nodemanager.hostname}:8048","fs.trash.checkpoint.interval":"0","yarn.nodemanager.opportunistic-containers-queue-policy":"BY_QUEUE_LEN","mapreduce.job.map.output.collector.class":"org.apache.hadoop.mapred.MapTask$MapOutputBuffer","yarn.federation.gpg.policy.generator.load-based.pending.maximum":"1000","yarn.resourcemanager.node-ip-cache.expiry-interval-secs":"-1","hadoop.http.authentication.signature.secret.file":"*********(redacted)","fs.s3a.committer.magic.track.commits.in.memory.enabled":"true","hadoop.jetty.logs.serve.aliases":"true","yarn.resourcemanager.placement-constraints.handler":"disabled","yarn.timeline-service.handler-thread-count":"10","yarn.resourcemanager.max-completed-applications":"1000","yarn.nodemanager.aux-services.manifest.enabled":"false","dfs.hosts.exclude":"/emr/instance-controller/lib/dfs.hosts.exclude","yarn.resourcemanager.system-metrics-publisher.enabled":"false","yarn.resourcemanager.placement-constraints.algorithm.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.constraint.algorithm.DefaultPlacementAlgorithm","yarn.sharedcache.webapp.address":"0.0.0.0:8788","fs.s3a.select.input.csv.quote.escape.character":"\\\\","yarn.resourcemanager.delegation.token.renew-interval":"*********(redacted)","yarn.sharedcache.nm.uploader.replication.factor":"10","hadoop.security.groups.negative-cache.secs":"30","yarn.app.mapreduce.task.container.log.backups":"0","mapreduce.reduce.skip.proc-count.auto-incr":"true","yarn.dispatcher.print-thread-pool.core-pool-size":"1","hadoop.security.group.mapping.ldap.posix.attr.gid.name":"gidNumber","ipc.client.fallback-to-simple-auth-allowed":"false","yarn.nodemanager.resource.memory.enforced":"true","yarn.federation.gpg.policy.generator.interval-ms":"3600000","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.enable-batch":"false","yarn.client.failover-proxy-provider":"org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider","yarn.federation.state-store.sql.idle-time-out":"10m","yarn.timeline-service.http-authentication.simple.anonymous.allowed":"true","ha.health-monitor.check-interval.ms":"1000","io.compression.codec.zstd.level":"3","yarn.nodemanager.runtime.linux.runc.host-pid-namespace.allowed":"false","hadoop.metrics.jvm.use-thread-mxbean":"false","ipc.[port_number].faircallqueue.multiplexer.weights":"8,4,2,1","yarn.acl.reservation-enable":"false","yarn.resourcemanager.store.class":"org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore","ipc.[port_number].callqueue.overflow.trigger.failover":"false","yarn.app.mapreduce.am.hard-kill-timeout-ms":"10000","fs.s3a.etag.checksum.enabled":"false","yarn.nodemanager.container-metrics.enable":"true","mapreduce.outputcommitter.factory.scheme.gs":"org.apache.hadoop.mapreduce.lib.output.committer.manifest.ManifestCommitterFactory","ha.health-monitor.rpc.connect.max.retries":"1","yarn.timeline-service.client.fd-clean-interval-secs":"60","yarn.resourcemanager.nodemanagers.heartbeat-interval-scaling-enable":"false","yarn.resourcemanager.nodemanagers.heartbeat-interval-ms":"1000","hadoop.common.configuration.version":"3.0.0","yarn.nodemanager.remote-app-log-dir-suffix":"logs","yarn.nodemanager.container-log-monitor.dir-size-limit-bytes":"1000000000","yarn.nodemanager.windows-container.cpu-limit.enabled":"false","yarn.nodemanager.runtime.linux.docker.privileged-containers.allowed":"false","file.blocksize":"67108864","hadoop.http.idle_timeout.ms":"60000","hadoop.registry.zk.retry.ceiling.ms":"60000","ipc.client.connection.idle-scan-interval.ms":"10000","yarn.scheduler.configuration.leveldb-store.path":"${hadoop.tmp.dir}/yarn/system/confstore","yarn.sharedcache.store.in-memory.initial-delay-mins":"10","mapreduce.jobhistory.principal":"jhs/_HOST@REALM.TLD","mapreduce.map.skip.proc-count.auto-incr":"true","fs.s3a.committer.name":"magicv2","mapreduce.task.profile.reduces":"0-2","hadoop.zk.num-retries":"1000","yarn.webapp.xfs-filter.enabled":"true","fs.viewfs.overload.scheme.target.hdfs.impl":"org.apache.hadoop.hdfs.DistributedFileSystem","seq.io.sort.mb":"100","fs.iostatistics.logging.level":"debug","yarn.scheduler.configuration.max.version":"100","yarn.timeline-service.webapp.https.address":"${yarn.timeline-service.hostname}:8190","yarn.resourcemanager.scheduler.address":"${yarn.resourcemanager.hostname}:8030","yarn.node-labels.enabled":"false","yarn.resourcemanager.webapp.ui-actions.enabled":"true","mapreduce.task.timeout":"600000","yarn.sharedcache.client-server.thread-count":"50","hadoop.security.groups.shell.command.timeout":"0s","hadoop.security.crypto.cipher.suite":"AES/CTR/NoPadding","yarn.nodemanager.elastic-memory-control.oom-handler":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.resources.DefaultOOMHandler","yarn.resourcemanager.connect.max-wait.ms":"900000","fs.defaultFS":"file:///","yarn.minicluster.use-rpc":"false","fs.s3.impl":"com.amazon.ws.emr.hadoop.fs.EmrFileSystem","ipc.[port_number].decay-scheduler.decay-factor":"0.5","fs.har.impl.disable.cache":"true","yarn.webapp.ui2.enable":"false","io.compression.codec.bzip2.library":"system-native","yarn.webapp.filter-invalid-xml-chars":"false","fs.s3.buckets.create.region":"us-east-1","yarn.nodemanager.runtime.linux.runc.layer-mounts-interval-secs":"600","fs.s3a.select.input.csv.record.delimiter":"\\n","fs.s3a.change.detection.source":"etag","ipc.[port_number].backoff.enable":"false","yarn.nodemanager.distributed-scheduling.enabled":"false","yarn.federation.cache.class":"org.apache.hadoop.yarn.server.federation.cache.FederationJCache","mapreduce.shuffle.connection-keep-alive.timeout":"5","yarn.resourcemanager.webapp.https.address":"${yarn.resourcemanager.hostname}:8090","yarn.webapp.enable-rest-app-submissions":"true","mapreduce.jobhistory.address":"0.0.0.0:10020","yarn.resourcemanager.nm-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.is.minicluster":"false","yarn.nodemanager.address":"${yarn.nodemanager.hostname}:0","hadoop.proxyuser.livy.groups":"*","fs.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","fs.AbstractFileSystem.s3a.impl":"org.apache.hadoop.fs.s3a.S3A","ipc.server.metrics.update.runner.interval":"5000","mapreduce.task.combine.progress.records":"10000","yarn.resourcemanager.epoch.range":"0","yarn.resourcemanager.am.max-attempts":"2","yarn.nodemanager.runtime.linux.runc.image-toplevel-dir":"/runc-root","yarn.nodemanager.linux-container-executor.cgroups.hierarchy":"/hadoop-yarn","io.compression.codec.lz4.use.lz4hc":"false","fs.AbstractFileSystem.wasbs.impl":"org.apache.hadoop.fs.azure.Wasbs","yarn.timeline-service.entity-group-fs-store.cache-store-class":"org.apache.hadoop.yarn.server.timeline.MemoryTimelineStore","yarn.nodemanager.runtime.linux.runc.allowed-container-networks":"host,none,bridge","fs.ftp.transfer.mode":"BLOCK_TRANSFER_MODE","ipc.server.log.slow.rpc":"false","ipc.server.reuseaddr":"true","fs.ftp.timeout":"0","yarn.resourcemanager.node-labels.provider.fetch-interval-ms":"1800000","fs.AbstractFileSystem.o3fs.impl":"org.apache.hadoop.fs.ozone.OzFs","yarn.router.webapp.https.address":"0.0.0.0:8091","yarn.resourcemanager.enable-node-untracked-without-include-path":"true","yarn.nodemanager.webapp.cross-origin.enabled":"false","yarn.federation.gpg.subcluster.heartbeat.expiration-ms":"30m","fs.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","yarn.resourcemanager.auto-update.containers":"false","yarn.app.mapreduce.am.job.committer.cancel-timeout":"60000","yarn.scheduler.configuration.zk-store.parent-path":"/confstore","yarn.nodemanager.default-container-executor.log-dirs.permissions":"710","yarn.app.attempt.diagnostics.limit.kc":"64","fs.viewfs.overload.scheme.target.swebhdfs.impl":"org.apache.hadoop.hdfs.web.SWebHdfsFileSystem","yarn.client.failover-no-ha-proxy-provider":"org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider","fs.s3a.change.detection.mode":"server","hadoop.proxyuser.presto.hosts":"*","ftp.bytes-per-checksum":"512","yarn.nodemanager.resource.memory-mb":"-1","io.compression.codecs":"org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec","fs.AbstractFileSystem.abfs.impl":"org.apache.hadoop.fs.azurebfs.Abfs","yarn.timeline-service.writer.flush-interval-seconds":"60","fs.s3a.fast.upload.active.blocks":"4","yarn.resourcemanager.submission-preprocessor.enabled":"false","hadoop.security.credential.clear-text-fallback":"true","yarn.nodemanager.collector-service.thread-count":"5","ipc.[port_number].scheduler.impl":"org.apache.hadoop.ipc.DefaultRpcScheduler","fs.azure.secure.mode":"false","mapreduce.jobhistory.joblist.cache.size":"20000","fs.ftp.host":"0.0.0.0","yarn.timeline-service.writer.async.queue.capacity":"100","yarn.router.webapp.appsinfo-cached-count":"100","yarn.resourcemanager.fs.state-store.num-retries":"0","yarn.resourcemanager.nodemanager-connect-retries":"10","yarn.nodemanager.log-aggregation.num-log-files-per-app":"30","hadoop.security.kms.client.encrypted.key.cache.low-watermark":"0.3f","fs.s3a.committer.magic.enabled":"true","yarn.timeline-service.client.max-retries":"30","dfs.ha.fencing.ssh.connect-timeout":"30000","yarn.log-aggregation-enable":"false","yarn.system-metrics-publisher.enabled":"false","mapreduce.reduce.markreset.buffer.percent":"0.0","fs.AbstractFileSystem.viewfs.impl":"org.apache.hadoop.fs.viewfs.ViewFs","yarn.resourcemanager.nodemanagers.heartbeat-interval-speedup-factor":"1.0","mapreduce.task.io.sort.factor":"48","yarn.nodemanager.amrmproxy.client.thread-count":"25","yarn.nodemanager.runtime.linux.docker.docker-client-credential-provider.class":"org.apache.hadoop.yarn.util.ReadConfigFileDockerClientCredentialProvider","ha.failover-controller.new-active.rpc-timeout.ms":"60000","yarn.nodemanager.container-localizer.java.opts":"-Xmx256m","mapreduce.jobhistory.datestring.cache.size":"200000","mapreduce.job.acl-modify-job":" ","yarn.nodemanager.windows-container.memory-limit.enabled":"false","yarn.timeline-service.webapp.address":"${yarn.timeline-service.hostname}:8188","yarn.app.mapreduce.am.job.committer.commit-window":"10000","yarn.nodemanager.container-manager.thread-count":"20","yarn.minicluster.fixed.ports":"false","hadoop.tags.system":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.cluster.max-application-priority":"0","yarn.timeline-service.ttl-enable":"true","mapreduce.jobhistory.recovery.store.fs.uri":"${hadoop.tmp.dir}/mapred/history/recoverystore","yarn.nodemanager.least-load-policy-selector.enabled":"false","yarn.nodemanager.least-load-policy-selector.pending-container.threshold":"10000","hadoop.caller.context.signature.max.size":"40","hadoop.proxyuser.hive.groups":"*","ipc.[port_number].decay-scheduler.backoff.responsetime.enable":"false","yarn.client.load.resource-types.from-server":"false","ha.zookeeper.session-timeout.ms":"10000","ipc.[port_number].decay-scheduler.metrics.top.user.count":"10","mapreduce.map.java.opts":"-Xmx2458m","tfile.io.chunk.size":"1048576","yarn.dispatcher.print-events-info.threshold":"5000","yarn.nodemanager.log-container-debug-info-on-error.enabled":"false","mapreduce.job.speculative.slowtaskthreshold":"1.0","io.serializations":"org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization","hadoop.security.kms.client.failover.sleep.max.millis":"2000","hadoop.security.group.mapping.ldap.directory.search.timeout":"10000","yarn.scheduler.configuration.store.max-logs":"1000","yarn.nodemanager.dispatcher.metric.enable":"false","yarn.nodemanager.node-attributes.provider.fetch-interval-ms":"600000","yarn.nodemanager.local-cache.max-files-per-directory":"8192","hadoop.http.cross-origin.enabled":"false","hadoop.zk.acl":"world:anyone:rwcda","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.num-manifests-to-cache":"10","mapreduce.map.sort.spill.percent":"0.80","yarn.timeline-service.entity-group-fs-store.scan-interval-seconds":"60","dfs.datanode.fsdataset.volume.choosing.policy":"org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy","yarn.node-attribute.fs-store.impl.class":"org.apache.hadoop.yarn.server.resourcemanager.nodelabels.FileSystemNodeAttributeStore","fs.s3a.retry.interval":"500ms","yarn.timeline-service.client.best-effort":"false","yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled":"*********(redacted)","hadoop.security.group.mapping.ldap.posix.attr.uid.name":"uidNumber","yarn.timeline-service.client.fd-forced-timeout-enabled":"false","fs.AbstractFileSystem.swebhdfs.impl":"org.apache.hadoop.fs.SWebHdfs","yarn.nodemanager.elastic-memory-control.timeout-sec":"5","fs.s3a.select.enabled":"true","mapreduce.ifile.readahead":"true","dynamodb.yarn.enabled":"false","yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms":"300000","yarn.timeline-service.reader.webapp.address":"${yarn.timeline-service.webapp.address}","yarn.resourcemanager.placement-constraints.algorithm.pool-size":"1","yarn.timeline-service.hbase.coprocessor.jar.hdfs.location":"/hbase/coprocessor/hadoop-yarn-server-timelineservice.jar","hadoop.security.kms.client.encrypted.key.cache.num.refill.threads":"2","yarn.webapp.ui1.tools.enable":"true","yarn.resourcemanager.scheduler.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler","yarn.app.mapreduce.am.command-opts":"-Xmx4915m","hadoop.http.sni.host.check.enabled":"false","mapreduce.cluster.local.dir":"/mnt/mapred,/mnt1/mapred","hadoop.proxyuser.hue.hosts":"*","io.mapfile.bloom.error.rate":"0.005","fs.client.resolve.topology.enabled":"false","hadoop.proxyuser.hue.groups":"*","yarn.nodemanager.runtime.linux.allowed-runtimes":"default","yarn.sharedcache.store.class":"org.apache.hadoop.yarn.server.sharedcachemanager.store.InMemorySCMStore","ha.failover-controller.graceful-fence.rpc-timeout.ms":"5000","ftp.replication":"3","fs.getspaceused.jitterMillis":"60000","hadoop.security.uid.cache.secs":"14400","mapreduce.job.maxtaskfailures.per.tracker":"3","ipc.scheduler.impl":"org.apache.hadoop.ipc.DefaultRpcScheduler","yarn.resourcemanager.zk-client-ssl.enabled":"false","io.skip.checksum.errors":"false","yarn.nodemanager.log.trigger.delete.by-size.enabled":"false","yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts":"3","yarn.timeline-service.webapp.xfs-filter.xframe-options":"SAMEORIGIN","fs.s3a.connection.timeout":"200s","yarn.app.mapreduce.am.webapp.https.enabled":"false","mapreduce.job.max.split.locations":"15","yarn.resourcemanager.nm-container-queuing.max-queue-length":"15","yarn.resourcemanager.delegation-token.always-cancel":"*********(redacted)","hadoop.registry.zk.session.timeout.ms":"60000","yarn.federation.cache-ttl.secs":"300","mapreduce.jvm.system-properties-to-log":"os.name,os.version,java.home,java.runtime.version,java.vendor,java.version,java.vm.name,java.class.path,java.io.tmpdir,user.dir,user.name","yarn.resourcemanager.opportunistic-container-allocation.nodes-used":"10","yarn.timeline-service.entity-group-fs-store.active-dir":"/tmp/entity-file-history/active","mapreduce.shuffle.transfer.buffer.size":"131072","yarn.timeline-service.client.retry-interval-ms":"1000","yarn.timeline-service.flowname.max-size":"0","yarn.http.policy":"HTTP_ONLY","fs.s3a.socket.send.buffer":"8192","fs.AbstractFileSystem.abfss.impl":"org.apache.hadoop.fs.azurebfs.Abfss","yarn.sharedcache.uploader.server.address":"0.0.0.0:8046","yarn.resourcemanager.delegation-token.max-conf-size-bytes":"*********(redacted)","hadoop.http.authentication.token.validity":"*********(redacted)","mapreduce.shuffle.max.connections":"0","yarn.minicluster.yarn.nodemanager.resource.memory-mb":"4096","mapreduce.job.emit-timeline-data":"false","yarn.nodemanager.resource.system-reserved-memory-mb":"-1","hadoop.kerberos.min.seconds.before.relogin":"60","mapreduce.jobhistory.move.thread-count":"3","yarn.resourcemanager.application-tag-based-placement.force-lowercase":"true","yarn.resourcemanager.admin.client.thread-count":"1","yarn.dispatcher.drain-events.timeout":"300000","ipc.[port_number].decay-scheduler.backoff.responsetime.thresholds":"10s,20s,30s,40s","fs.s3a.buffer.dir":"${env.LOCAL_DIRS:-${hadoop.tmp.dir}}/s3a","hadoop.ssl.enabled.protocols":"TLSv1.2","mapreduce.jobhistory.admin.address":"0.0.0.0:10033","yarn.log-aggregation-status.time-out.ms":"600000","ipc.server.max.response.size":"1048576","fs.s3a.accesspoint.required":"false","mapreduce.shuffle.port":"13562","yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory":"10","yarn.nodemanager.health-checker.interval-ms":"600000","yarn.resourcemanager.proxy.connection.timeout":"60000","yarn.router.clientrm.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.clientrm.DefaultClientRequestInterceptor","yarn.resourcemanager.zk-appid-node.split-index":"0","ftp.blocksize":"67108864","yarn.nodemanager.runtime.linux.sandbox-mode.local-dirs.permissions":"read","yarn.router.rmadmin.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor","yarn.nodemanager.log-container-debug-info.enabled":"true","yarn.resourcemanager.activities-manager.app-activities.max-queue-length":"100","yarn.resourcemanager.application-https.policy":"NONE","yarn.client.max-cached-nodemanagers-proxies":"0","yarn.nodemanager.linux-container-executor.cgroups.delete-delay-ms":"20","yarn.nodemanager.delete.debug-delay-sec":"0","yarn.nodemanager.pmem-check-enabled":"true","yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage":"90.0","mapreduce.app-submission.cross-platform":"false","yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms":"10000","yarn.nodemanager.container-retry-minimum-interval-ms":"1000","yarn.federation.gpg.application.cleaner.contact.router.spec":"3,10,600000","hadoop.security.groups.cache.secs":"300","yarn.federation.enabled":"false","yarn.workflow-id.tag-prefix":"workflowid:","fs.azure.local.sas.key.mode":"false","yarn.federation.gpg.policy.generator.class":"org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator.NoOpGlobalPolicy","ipc.maximum.data.length":"134217728","mapreduce.shuffle.max.threads":"0","yarn.router.pipeline.cache-max-size":"25","yarn.resourcemanager.nm-container-queuing.load-comparator":"QUEUE_LENGTH","ipc.server.tcpnodelay":"true","yarn.resourcemanager.resource-tracker.nm.ip-hostname-check":"false","hadoop.security.authorization":"false","yarn.app.mapreduce.am.jhs.backup.enabled":"true","mapreduce.job.complete.cancel.delegation.tokens":"*********(redacted)","fs.s3a.paging.maximum":"5000","nfs.exports.allowed.hosts":"* rw","yarn.nodemanager.amrmproxy.ha.enable":"false","yarn.router.webapp.appsinfo-enabled":"false","fs.AbstractFileSystem.gs.impl":"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS","mapreduce.jobhistory.http.policy":"HTTP_ONLY","yarn.sharedcache.store.in-memory.check-period-mins":"720","mapreduce.reduce.java.opts":"-Xmx4916m","hive.metastore.client.factory.class":"com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory","hadoop.security.group.mapping.ldap.ssl":"false","fs.s3a.downgrade.syncable.exceptions":"true","yarn.client.application-client-protocol.poll-interval-ms":"200","yarn.scheduler.configuration.leveldb-store.compaction-interval-secs":"86400","yarn.timeline-service.writer.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineWriterImpl","ha.zookeeper.parent-znode":"/hadoop-ha","yarn.resourcemanager.submission-preprocessor.file-refresh-interval-ms":"60000","dfs.namenode.safemode.extension":"5000","yarn.nodemanager.log-aggregation.policy.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.AllContainerLogAggregationPolicy","mapreduce.reduce.shuffle.merge.percent":"0.66","hadoop.security.group.mapping.ldap.search.filter.group":"(objectClass=group)","yarn.resourcemanager.placement-constraints.scheduler.pool-size":"1","yarn.resourcemanager.activities-manager.cleanup-interval-ms":"5000","yarn.nodemanager.resourcemanager.minimum.version":"NONE","mapreduce.job.speculative.speculative-cap-running-tasks":"0.1","yarn.admin.acl":"*","dfs.namenode.replication.max-streams-hard-limit":"40","ipc.[port_number].identity-provider.impl":"org.apache.hadoop.ipc.UserIdentityProvider","yarn.nodemanager.recovery.supervised":"false","yarn.sharedcache.admin.thread-count":"1","yarn.resourcemanager.ha.automatic-failover.enabled":"true","yarn.nodemanager.container-log-monitor.total-size-limit-bytes":"10000000000","mapreduce.reduce.skip.maxgroups":"0","mapreduce.reduce.shuffle.connect.timeout":"180000","yarn.federation.amrmproxy.register.uam.retry-count":"3","yarn.nodemanager.health-checker.scripts":"script","yarn.resourcemanager.address":"${yarn.resourcemanager.hostname}:8032","ipc.client.ping":"true","mapreduce.task.local-fs.write-limit.bytes":"-1","mapred.output.committer.class":"org.apache.hadoop.mapred.DirectFileOutputCommitter","fs.adl.oauth2.access.token.provider.type":"*********(redacted)","mapreduce.shuffle.ssl.file.buffer.size":"65536","yarn.resourcemanager.ha.automatic-failover.embedded":"true","yarn.nodemanager.resource-plugins.gpu.docker-plugin":"nvidia-docker-v1","fs.s3a.multipart.purge":"false","yarn.scheduler.configuration.store.class":"file","yarn.resourcemanager.nm-container-queuing.queue-limit-stdev":"1.0f","mapreduce.job.end-notification.max.attempts":"5","mapreduce.output.fileoutputformat.compress.codec":"org.apache.hadoop.io.compress.DefaultCodec","yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled":"false","ipc.client.bind.wildcard.addr":"false","yarn.resourcemanager.webapp.rest-csrf.enabled":"false","ha.health-monitor.connect-retry-interval.ms":"1000","yarn.nodemanager.keytab":"/etc/krb5.keytab","hadoop.security.resolver.impl":"org.apache.hadoop.net.DNSDomainNameResolver","hive.metastore.connect.retries":"15","mapreduce.jobhistory.keytab":"/etc/security/keytab/jhs.service.keytab","fs.s3a.threads.max":"96","yarn.nodemanager.runtime.linux.docker.image-update":"false","mapreduce.reduce.shuffle.input.buffer.percent":"0.70","fs.viewfs.overload.scheme.target.abfss.impl":"org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystem","yarn.dispatcher.cpu-monitor.samples-per-min":"60","hadoop.security.token.service.use_ip":"*********(redacted)","yarn.nodemanager.runtime.linux.docker.allowed-container-networks":"host,none,bridge","yarn.nodemanager.node-labels.resync-interval-ms":"120000","hadoop.tmp.dir":"/tmp/hadoop","mapreduce.job.maps":"16","mapreduce.jobhistory.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.job.end-notification.max.retry.interval":"5000","yarn.log-aggregation.retain-check-interval-seconds":"-1","yarn.resourcemanager.resource-tracker.client.thread-count":"50","yarn.nodemanager.containers-launcher.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher","yarn.resourcemanager.decommissioning-nodes-watcher.wait-for-applications":"true","yarn.rm.system-metrics-publisher.emit-container-events":"false","yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size":"10000","yarn.resourcemanager.ha.automatic-failover.zk-base-path":"/yarn-leader-election","io.seqfile.local.dir":"${hadoop.tmp.dir}/io/local","fs.AbstractFileSystem.wasb.impl":"org.apache.hadoop.fs.azure.Wasb","mapreduce.client.submit.file.replication":"10","mapreduce.jobhistory.minicluster.fixed.ports":"false","fs.s3a.multipart.threshold":"128M","yarn.resourcemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","ipc.callqueue.impl":"java.util.concurrent.LinkedBlockingQueue","mapreduce.jobhistory.done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done","ipc.server.purge.interval":"15","dfs.namenode.name.dir":"file:///mnt/namenode","ipc.client.idlethreshold":"4000","yarn.nodemanager.linux-container-executor.cgroups.strict-resource-usage":"false","mapreduce.reduce.input.buffer.percent":"0.0","yarn.nodemanager.runtime.linux.docker.userremapping-gid-threshold":"1","yarn.nodemanager.webapp.rest-csrf.enabled":"false","fs.ftp.host.port":"21","ipc.ping.interval":"60000","yarn.resourcemanager.history-writer.multi-threaded-dispatcher.pool-size":"10","yarn.router.interceptor.user-thread-pool.maximum-pool-size":"5","yarn.resourcemanager.admin.address":"${yarn.resourcemanager.hostname}:8033","file.client-write-packet-size":"65536","ipc.client.kill.max":"10","mapreduce.reduce.speculative":"true","hadoop.security.key.default.bitlength":"256","mapreduce.job.reducer.unconditional-preempt.delay.sec":"300","yarn.nodemanager.disk-health-checker.interval-ms":"120000","yarn.nodemanager.log.deletion-threads-count":"4","fs.s3a.committer.abort.pending.uploads":"true","yarn.webapp.filter-entity-list-by-user":"false","yarn.resourcemanager.activities-manager.app-activities.ttl-ms":"600000","ipc.client.connection.maxidletime":"10000","mapreduce.task.io.sort.mb":"200","yarn.nodemanager.localizer.client.thread-count":"5","yarn.federation.gpg.policy.generator.load-based.edit.maximum":"3","io.erasurecode.codec.rs.rawcoders":"rs_native,rs_java","io.erasurecode.codec.rs-legacy.rawcoders":"rs-legacy_java","yarn.sharedcache.admin.address":"0.0.0.0:8047","yarn.resourcemanager.placement-constraints.algorithm.iterator":"SERIAL","yarn.nodemanager.localizer.cache.cleanup.interval-ms":"600000","hadoop.security.crypto.codec.classes.aes.ctr.nopadding":"org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec, org.apache.hadoop.crypto.JceAesCtrCryptoCodec","mapreduce.job.cache.limit.max-resources-mb":"0","fs.s3a.connection.ssl.enabled":"true","yarn.nodemanager.process-kill-wait.ms":"5000","mapreduce.job.hdfs-servers":"${fs.defaultFS}","yarn.apps.cache.size":"1000","yarn.app.mapreduce.am.webapp.https.client.auth":"false","hadoop.workaround.non.threadsafe.getpwuid":"true","fs.df.interval":"60000","ipc.[port_number].decay-scheduler.thresholds":"13,25,50","yarn.federation.gpg.webapp.https.address":"0.0.0.0:8070","ipc.server.read.threadpool.size":"1","fs.s3a.audit.enabled":"true","fs.s3a.multiobjectdelete.enable":"true","yarn.sharedcache.cleaner.resource-sleep-ms":"0","ipc.server.read.connection-queue.size":"100","yarn.nodemanager.disk-health-checker.min-healthy-disks":"0.25","hadoop.shell.missing.defaultFs.warning":"false","io.file.buffer.size":"65536","fs.viewfs.overload.scheme.target.wasb.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem","dfs.permissions.superusergroup":"hadoop","hadoop.security.group.mapping.ldap.search.attr.member":"member","yarn.nodemanager.shuffledata-monitor.interval-ms":"30000","hadoop.security.random.device.file.path":"/dev/urandom","ipc.cost-provider.impl":"org.apache.hadoop.ipc.DefaultCostProvider","hadoop.security.sensitive-config-keys":"*********(redacted)","fs.viewfs.overload.scheme.target.file.impl":"org.apache.hadoop.fs.LocalFileSystem","yarn.federation.gpg.application.cleaner.interval-ms":"-1s","hadoop.rpc.socket.factory.class.default":"org.apache.hadoop.net.StandardSocketFactory","yarn.intermediate-data-encryption.enable":"false","yarn.nodemanager.least-load-policy-selector.use-active-core":"false","yarn.resourcemanager.connect.retry-interval.ms":"30000","yarn.nodemanager.container.stderr.pattern":"{*stderr*,*STDERR*}","fs.s3bfs.impl":"org.apache.hadoop.fs.s3.S3FileSystem","yarn.apps.cache.expire":"30s","ipc.server.log.slow.rpc.threshold.ms":"0","yarn.scheduler.minimum-allocation-mb":"1024","yarn.app.mapreduce.am.staging-dir":"/tmp/hadoop-yarn/staging","mapreduce.reduce.shuffle.read.timeout":"180000","fs.s3.customAWSCredentialsProvider":"com.amazonaws.auth.DefaultAWSCredentialsProviderChain","hadoop.http.cross-origin.max-age":"1800","io.erasurecode.codec.xor.rawcoders":"xor_native,xor_java","fs.s3a.connection.establish.timeout":"5s","mapreduce.job.running.map.limit":"0","yarn.minicluster.control-resource-monitoring":"false","hadoop.ssl.require.client.cert":"false","hadoop.kerberos.kinit.command":"kinit","yarn.apps.cache.enable":"false","yarn.federation.non-ha.enabled":"false","yarn.federation.state-store.class":"org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore","yarn.federation.state-store.heartbeat.initial-delay":"30s","mapreduce.reduce.log.level":"INFO","hadoop.security.dns.log-slow-lookups.threshold.ms":"1000","mapreduce.job.ubertask.enable":"false","adl.http.timeout":"-1","yarn.resourcemanager.placement-constraints.retry-attempts":"3","hadoop.caller.context.enabled":"false","hadoop.security.group.mapping.ldap.num.attempts":"3","yarn.nodemanager.vmem-pmem-ratio":"2.1","hadoop.rpc.protection":"authentication","ha.health-monitor.rpc-timeout.ms":"45000","yarn.nodemanager.remote-app-log-dir":"/tmp/logs","hadoop.zk.timeout-ms":"10000","yarn.nodemanager.resource.pcores-vcores-multiplier":"1.0","yarn.nodemanager.runtime.linux.sandbox-mode":"disabled","ipc.client.connect.max.retries.on.sasl":"5","yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size":"10","fs.viewfs.overload.scheme.target.webhdfs.impl":"org.apache.hadoop.hdfs.web.WebHdfsFileSystem","yarn.router.webapp.proxy.enable":"true","fs.s3a.committer.threads":"8","hadoop.zk.retry-interval-ms":"1000","hadoop.http.metrics.enabled":"true","hadoop.security.crypto.buffer.size":"8192","yarn.nodemanager.node-labels.provider.fetch-interval-ms":"600000","mapreduce.jobhistory.recovery.store.leveldb.path":"${hadoop.tmp.dir}/mapred/history/recoverystore","yarn.client.failover-retries-on-socket-timeouts":"0","fs.s3a.ssl.channel.mode":"default_jsse","yarn.nodemanager.resource.memory.enabled":"false","fs.azure.authorization.caching.enable":"true","hadoop.security.instrumentation.requires.admin":"false","yarn.nodemanager.delete.thread-count":"4","mapreduce.job.finish-when-all-reducers-done":"true","hadoop.registry.jaas.context":"Client","yarn.resourcemanager.delegation.token.remove-scan-interval":"*********(redacted)","yarn.timeline-service.leveldb-timeline-store.path":"${hadoop.tmp.dir}/yarn/timeline","io.map.index.interval":"128","yarn.resourcemanager.nm-container-queuing.max-queue-wait-time-ms":"100","fs.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","mapreduce.job.counters.max":"120","ipc.identity-provider.impl":"org.apache.hadoop.ipc.UserIdentityProvider","mapreduce.jobhistory.webapp.rest-csrf.enabled":"false","yarn.timeline-service.store-class":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.jobhistory.move.interval-ms":"180000","yarn.federation.amrmproxy.register.uam.interval":"100ms","yarn.resourcemanager.node-labels.provider.update-newly-registered-nodes-interval-ms":"30000","fs.s3a.change.detection.version.required":"true","yarn.nodemanager.localizer.fetch.thread-count":"4","yarn.resourcemanager.scheduler.client.thread-count":"50","hadoop.ssl.hostname.verifier":"DEFAULT","yarn.timeline-service.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/timeline","mapreduce.job.classloader":"false","mapreduce.task.profile.map.params":"${mapreduce.task.profile.params}","ipc.client.connect.timeout":"20000","hadoop.security.auth_to_local.mechanism":"hadoop","yarn.timeline-service.app-collector.linger-period.ms":"60000","yarn.fs-store.file.replication":"0","yarn.nm.liveness-monitor.expiry-interval-ms":"600000","yarn.resourcemanager.reservation-system.planfollower.time-step":"1000","yarn.resourcemanager.proxy.timeout.enabled":"true","yarn.resourcemanager.activities-manager.scheduler-activities.ttl-ms":"600000","yarn.nodemanager.runtime.linux.docker.enable-userremapping.allowed":"true","hadoop.proxyuser.hadoop.groups":"*","yarn.webapp.api-service.enable":"false","yarn.nodemanager.recovery.enabled":"false","mapreduce.job.end-notification.retry.interval":"1000","fs.du.interval":"600000","fs.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","yarn.nodemanager.container.stderr.tail.bytes":"4096","yarn.nodemanager.disk-health-checker.disk-free-space-threshold.enabled":"true","io.compression.codec.snappy.buffersize":"262144","hadoop.security.group.mapping.ldap.read.timeout.ms":"60000","hadoop.security.groups.cache.warn.after.ms":"5000","file.bytes-per-checksum":"512","mapreduce.outputcommitter.factory.scheme.s3a":"org.apache.hadoop.fs.s3a.commit.S3ACommitterFactory","io.erasurecode.codec.native.enabled":"true","hadoop.security.groups.cache.background.reload":"false","yarn.nodemanager.container-monitor.enabled":"true","yarn.nodemanager.elastic-memory-control.enabled":"false","fs.AbstractFileSystem.ofs.impl":"org.apache.hadoop.fs.ozone.RootedOzFs","net.topology.script.number.args":"100","mapreduce.task.merge.progress.records":"10000","yarn.nodemanager.localizer.address":"${yarn.nodemanager.hostname}:8040","yarn.timeline-service.keytab":"/etc/krb5.keytab","mapreduce.reduce.shuffle.fetch.retry.timeout-ms":"30000","yarn.resourcemanager.rm.container-allocation.expiry-interval-ms":"600000","yarn.nodemanager.container-executor.exit-code-file.timeout-ms":"2000","mapreduce.fileoutputcommitter.algorithm.version":"2","yarn.router.webapp.cross-origin.enabled":"false","yarn.resourcemanager.work-preserving-recovery.enabled":"true","mapreduce.map.skip.maxrecords":"0","yarn.sharedcache.root-dir":"/sharedcache","fs.s3a.retry.throttle.limit":"20","yarn.nodemanager.master-hostname-resolution-check.interval-ms":"12000","fs.trash.clean.trashroot.enable":"false","hadoop.http.authentication.type":"simple","fs.viewfs.overload.scheme.target.oss.impl":"org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem","mapreduce.job.jvm.numtasks":"20","yarn.federation.gpg.policy.generator.interval":"1h","mapreduce.job.cache.limit.max-resources":"0","mapreduce.task.userlog.limit.kb":"0","ipc.[port_number].weighted-cost.handler":"1","yarn.resourcemanager.scheduler.monitor.enable":"false","ipc.client.connect.max.retries":"10","hadoop.registry.zk.retry.times":"5","yarn.nodemanager.resource-monitor.interval-ms":"3000","yarn.nodemanager.resource-plugins.gpu.allowed-gpu-devices":"auto","mapreduce.job.sharedcache.mode":"disabled","yarn.app.mapreduce.am.jhs.backup-dir":"file:///var/log/hadoop-mapreduce/history","yarn.federation.state-store.sql.minimum-idle":"1","yarn.nodemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.shuffle.listen.queue.size":"128","yarn.scheduler.configuration.mutation.acl-policy.class":"org.apache.hadoop.yarn.server.resourcemanager.scheduler.DefaultConfigurationMutationACLPolicy","yarn.federation.gpg.subcluster.cleaner.interval-ms":"-1ms","mapreduce.map.cpu.vcores":"1","yarn.log-aggregation.file-formats":"TFile","yarn.timeline-service.client.fd-retain-secs":"300","fs.s3a.select.output.csv.field.delimiter":",","yarn.nodemanager.health-checker.timeout-ms":"1200000","yarn.resourcemanager.decommissioning.node.max.allocation.enabled":"false","hadoop.user.group.static.mapping.overrides":"dr.who=;","fs.azure.sas.expiry.period":"90d","fs.s3a.select.output.csv.record.delimiter":"\\n","mapreduce.jobhistory.recovery.store.class":"org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService","fs.viewfs.overload.scheme.target.https.impl":"org.apache.hadoop.fs.http.HttpsFileSystem","yarn.federation.gpg.policy.generator.readonly":"false","yarn.router.deregister.subcluster.enabled":"true","yarn.resourcemanager.fail-fast":"${yarn.fail-fast}","yarn.resourcemanager.proxy-user-privileges.enabled":"false","yarn.router.webapp.interceptor-class.pipeline":"org.apache.hadoop.yarn.server.router.webapp.DefaultRequestInterceptorREST","yarn.nodemanager.resource.memory.cgroups.soft-limit-percentage":"90.0","mapreduce.job.reducer.preempt.delay.sec":"0","hadoop.util.hash.type":"murmur","yarn.nodemanager.disk-validator":"basic","yarn.app.mapreduce.client.job.max-retries":"3","fs.viewfs.overload.scheme.target.ftp.impl":"org.apache.hadoop.fs.ftp.FTPFileSystem","mapreduce.reduce.shuffle.retry-delay.max.ms":"60000","hadoop.security.group.mapping.ldap.connection.timeout.ms":"60000","mapreduce.task.profile.params":"-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s","yarn.app.mapreduce.shuffle.log.backups":"0","yarn.nodemanager.container-diagnostics-maximum-size":"10000","hadoop.registry.zk.retry.interval.ms":"1000","yarn.federation.gpg.scheduled.executor.threads":"10","yarn.nodemanager.linux-container-executor.cgroups.delete-timeout-ms":"1000","yarn.nodemanager.aux-services.%s.classpath":"NONE","fs.AbstractFileSystem.file.impl":"org.apache.hadoop.fs.local.LocalFs","yarn.federation.gpg.webapp.connect-timeout":"30s","yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds":"-1","mapreduce.jobhistory.cleaner.interval-ms":"86400000","hadoop.registry.zk.quorum":"localhost:2181","yarn.nodemanager.runtime.linux.runc.allowed-container-runtimes":"runc","mapreduce.output.fileoutputformat.compress":"false","yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs":"*********(redacted)","fs.s3a.assumed.role.session.duration":"30m","hadoop.security.group.mapping.ldap.conversion.rule":"none","hadoop.proxyuser.livy.hosts":"*","hadoop.ssl.server.conf":"ssl-server.xml","fs.s3a.retry.throttle.interval":"100ms","yarn.router.subcluster.cleaner.interval.time":"60s","yarn.nodemanager.log.delete.threshold":"100g","seq.io.sort.factor":"100","fs.viewfs.overload.scheme.target.ofs.impl":"org.apache.hadoop.fs.ozone.RootedOzoneFileSystem","yarn.sharedcache.cleaner.initial-delay-mins":"10","mapreduce.client.completion.pollinterval":"5000","hadoop.ssl.keystores.factory.class":"org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory","yarn.resourcemanager.nodestore-rootdir.retry-interval-ms":"1000","yarn.app.mapreduce.am.resource.cpu-vcores":"1","yarn.timeline-service.enabled":"false","yarn.nodemanager.runtime.linux.docker.capabilities":"CHOWN,DAC_OVERRIDE,FSETID,FOWNER,MKNOD,NET_RAW,SETGID,SETUID,SETFCAP,SETPCAP,NET_BIND_SERVICE,SYS_CHROOT,KILL,AUDIT_WRITE","yarn.acl.enable":"false","yarn.timeline-service.entity-group-fs-store.done-dir":"/tmp/entity-file-history/done/","mapreduce.tasktracker.map.tasks.maximum":"1","hadoop.security.group.mapping.ldap.num.attempts.before.failover":"3","mapreduce.task.profile":"false","yarn.federation.gpg.application.cleaner.class":"org.apache.hadoop.yarn.server.globalpolicygenerator.applicationcleaner.DefaultApplicationCleaner","hadoop.prometheus.endpoint.enabled":"false","dfs.webhdfs.enabled":"true","yarn.resourcemanager.fs.state-store.uri":"${hadoop.tmp.dir}/yarn/system/rmstore","mapreduce.jobhistory.always-scan-user-dir":"false","yarn.nodemanager.opportunistic-containers-use-pause-for-preemption":"false","yarn.nodemanager.linux-container-executor.nonsecure-mode.local-user":"nobody","mapred.output.direct.EmrFileSystem":"true","yarn.timeline-service.reader.class":"org.apache.hadoop.yarn.server.timelineservice.storage.HBaseTimelineReaderImpl","yarn.resourcemanager.configuration.provider-class":"org.apache.hadoop.yarn.LocalConfigurationProvider","yarn.nodemanager.runtime.linux.docker.userremapping-uid-threshold":"1","yarn.resourcemanager.configuration.file-system-based-store":"/yarn/conf","lakeformation.credentials.url":"http://localhost:9998/lakeformationcredentials","fs.creation.parallel.count":"64","mapreduce.job.cache.limit.max-single-resource-mb":"0","yarn.nodemanager.runtime.linux.docker.stop.grace-period":"10","yarn.federation.state-store.sql.max-life-time":"30m","yarn.resourcemanager.resource-profiles.source-file":"resource-profiles.json","mapreduce.job.dfs.storage.capacity.kill-limit-exceed":"false","yarn.nodemanager.resource.percentage-physical-cpu-limit":"100","mapreduce.jobhistory.client.thread-count":"10","tfile.fs.input.buffer.size":"262144","mapreduce.client.progressmonitor.pollinterval":"1000","yarn.nodemanager.log-dirs":"${yarn.log.dir}/userlogs","hadoop.security.auth_to_local":"\n      RULE:[1:$1@$0](.*@)s/@.*///L\n      RULE:[2:$1@$0](.*@)s/@.*///L\n      DEFAULT\n    ","yarn.resourcemanager.opportunistic.max.container-allocation.per.am.heartbeat":"-1","fs.automatic.close":"true","yarn.resourcemanager.delegation-token-renewer.thread-retry-interval":"*********(redacted)","yarn.resourcemanager.node-labels.am.allow-non-exclusive-allocation":"false","fs.s3a.select.input.csv.quote.character":"\"","yarn.nodemanager.hostname":"0.0.0.0","ipc.[port_number].cost-provider.impl":"org.apache.hadoop.ipc.DefaultCostProvider","yarn.nodemanager.runtime.linux.runc.manifest-to-resources-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.HdfsManifestToResourcesPlugin","yarn.nodemanager.remote-app-log-dir-include-older":"true","yarn.nodemanager.resource.memory.cgroups.swappiness":"0","fs.s3n.impl":"com.amazon.ws.emr.hadoop.fs.EmrFileSystem","ftp.stream-buffer-size":"4096","yarn.fail-fast":"false","yarn.nodemanager.runtime.linux.runc.layer-mounts-to-keep":"100","yarn.timeline-service.app-aggregation-interval-secs":"15","hadoop.security.group.mapping.ldap.search.filter.user":"(&(objectClass=user)(sAMAccountName={0}))","yarn.resourcemanager.nodestore-rootdir.num-retries":"1000","ipc.[port_number].weighted-cost.lockshared":"10","yarn.nodemanager.container-localizer.log.level":"INFO","yarn.timeline-service.address":"${yarn.timeline-service.hostname}:10200","dfs.namenode.replication.work.multiplier.per.iteration":"10","mapreduce.job.ubertask.maxmaps":"9","fs.s3.consistent.metadata.etag.verification.enabled":"false","fs.s3a.threads.keepalivetime":"60s","dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction":"1.0","mapreduce.jobhistory.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.task.files.preserve.failedtasks":"false","yarn.app.mapreduce.client.job.retry-interval":"2000","ha.failover-controller.graceful-fence.connection.retries":"1","fs.s3a.select.output.csv.quote.escape.character":"\\\\","yarn.dispatcher.print-thread-pool.maximum-pool-size":"5","yarn.resourcemanager.delegation.token.max-lifetime":"*********(redacted)","hadoop.kerberos.keytab.login.autorenewal.enabled":"false","yarn.timeline-service.client.drain-entities.timeout.ms":"2000","hadoop.caller.context.separator":",","yarn.nodemanager.resource-plugins.fpga.vendor-plugin.class":"org.apache.hadoop.yarn.server.nodemanager.containermanager.resourceplugin.fpga.IntelFpgaOpenclPlugin","yarn.resourcemanager.nodemanagers.heartbeat-interval-min-ms":"1000","yarn.timeline-service.entity-group-fs-store.summary-store":"org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore","mapreduce.reduce.cpu.vcores":"1","hadoop.proxyuser.oozie.groups":"*","mapreduce.job.encrypted-intermediate-data.buffer.kb":"128","hadoop.security.crypto.codec.classes.sm4.ctr.nopadding":"org.apache.hadoop.crypto.OpensslSm4CtrCryptoCodec, org.apache.hadoop.crypto.JceSm4CtrCryptoCodec","yarn.federation.gpg.webapp.read-timeout":"30s","fs.client.resolve.remote.symlinks":"true","yarn.nodemanager.webapp.https.address":"0.0.0.0:8044","hadoop.http.cross-origin.allowed-origins":"*","mapreduce.job.encrypted-intermediate-data":"false","yarn.nodemanager.disk-health-checker.disk-utilization-threshold.enabled":"true","fs.s3a.executor.capacity":"16","yarn.timeline-service.entity-group-fs-store.retain-seconds":"604800","yarn.resourcemanager.metrics.runtime.buckets":"60,300,1440","yarn.timeline-service.generic-application-history.max-applications":"10000","mapreduce.tasktracker.reduce.tasks.maximum":"1","yarn.nodemanager.local-dirs":"${hadoop.tmp.dir}/nm-local-dir","mapreduce.shuffle.connection-keep-alive.enable":"false","yarn.node-labels.configuration-type":"centralized","fs.s3a.path.style.access":"false","yarn.nodemanager.aux-services.mapreduce_shuffle.class":"org.apache.hadoop.mapred.ShuffleHandler","yarn.sharedcache.store.in-memory.staleness-period-mins":"10080","fs.adl.impl":"org.apache.hadoop.fs.adl.AdlFileSystem","yarn.resourcemanager.application.max-tags":"10","hadoop.domainname.resolver.impl":"org.apache.hadoop.net.DNSDomainNameResolver","yarn.resourcemanager.nodemanager.minimum.version":"NONE","mapreduce.jobhistory.webapp.xfs-filter.xframe-options":"SAMEORIGIN","yarn.app.mapreduce.am.staging-dir.erasurecoding.enabled":"false","net.topology.impl":"org.apache.hadoop.net.NetworkTopology","io.map.index.skip":"0","fs.AbstractFileSystem.s3.impl":"org.apache.hadoop.fs.s3.EMRFSDelegate","yarn.timeline-service.reader.webapp.https.address":"${yarn.timeline-service.webapp.https.address}","fs.ftp.data.connection.mode":"ACTIVE_LOCAL_DATA_CONNECTION_MODE","mapreduce.job.userlog.retain.hours":"48","mapreduce.job.local-fs.single-disk-limit.check.kill-limit-exceed":"true","fs.azure.buffer.dir":"${env.LOCAL_DIRS:-${hadoop.tmp.dir}}/abfs","yarn.scheduler.maximum-allocation-vcores":"4","hadoop.http.cross-origin.allowed-headers":"X-Requested-With,Content-Type,Accept,Origin","yarn.nodemanager.log-aggregation.compression-type":"none","yarn.timeline-service.version":"1.0f","yarn.ipc.rpc.class":"org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC","mapreduce.reduce.maxattempts":"4","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.batch-size":"1000","hadoop.security.dns.log-slow-lookups.enabled":"false","mapreduce.job.committer.setup.cleanup.needed":"true","hadoop.security.secure.random.impl":"org.apache.hadoop.crypto.random.OpensslSecureRandom","mapreduce.job.running.reduce.limit":"0","fs.s3a.select.errors.include.sql":"false","ipc.maximum.response.length":"134217728","yarn.resourcemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","mapreduce.job.token.tracking.ids.enabled":"*********(redacted)","hadoop.caller.context.max.size":"128","yarn.nodemanager.runtime.linux.docker.host-pid-namespace.allowed":"false","yarn.nodemanager.runtime.linux.docker.delayed-removal.allowed":"false","hadoop.registry.system.acls":"sasl:yarn@, sasl:mapred@, sasl:hdfs@","yarn.nodemanager.recovery.dir":"${hadoop.tmp.dir}/yarn-nm-recovery","yarn.federation.gpg.policy.generator.load-based.weight.minimum":"0","fs.s3a.fast.upload.buffer":"disk","mapreduce.jobhistory.intermediate-done-dir":"${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate","yarn.app.mapreduce.shuffle.log.separate":"true","yarn.log-aggregation.debug.filesize":"104857600","yarn.dispatcher.print-thread-pool.keep-alive-time":"10s","yarn.router.subcluster.heartbeat.expiration.time":"30m","fs.s3a.max.total.tasks":"32","fs.s3a.readahead.range":"64K","hadoop.http.authentication.simple.anonymous.allowed":"true","yarn.nodemanager.master-hostname-resolution-check.enable":"true","fs.s3a.attempts.maximum":"5","yarn.federation.amrmproxy.allocation.history.max.entry":"100","hadoop.registry.zk.connection.timeout.ms":"15000","yarn.resourcemanager.delegation-token-renewer.thread-count":"*********(redacted)","yarn.resourcemanager.delegation-token-renewer.thread-timeout":"*********(redacted)","yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size":"10000","yarn.nodemanager.aux-services.manifest.reload-ms":"0","yarn.nodemanager.emit-container-events":"true","yarn.resourcemanager.resource-profiles.enabled":"false","yarn.timeline-service.hbase-schema.prefix":"prod.","fs.azure.authorization":"false","mapreduce.map.log.level":"INFO","ha.failover-controller.active-standby-elector.zk.op.retries":"3","yarn.resourcemanager.decommissioning-nodes-watcher.poll-interval-secs":"20","hadoop.job.history.user.location":"none","mapreduce.output.fileoutputformat.compress.type":"BLOCK","yarn.resourcemanager.leveldb-state-store.path":"${hadoop.tmp.dir}/yarn/system/rmstore","yarn.timeline-service.webapp.rest-csrf.custom-header":"X-XSRF-Header","mapreduce.task.spill.files.count.limit":"-1","mapreduce.ifile.readahead.bytes":"4194304","yarn.sharedcache.app-checker.class":"org.apache.hadoop.yarn.server.sharedcachemanager.RemoteAppChecker","yarn.nodemanager.linux-container-executor.nonsecure-mode.limit-users":"true","yarn.nodemanager.resource.detect-hardware-capabilities":"false","mapreduce.cluster.acls.enabled":"false","mapreduce.job.speculative.retry-after-no-speculate":"1000","fs.viewfs.overload.scheme.target.abfs.impl":"org.apache.hadoop.fs.azurebfs.AzureBlobFileSystem","yarn.federation.gpg.webapp.address":"0.0.0.0:8069","hadoop.security.group.mapping.ldap.search.group.hierarchy.levels":"0","yarn.resourcemanager.fs.state-store.retry-interval-ms":"1000","hadoop.proxyuser.hadoop.hosts":"*","file.stream-buffer-size":"4096","yarn.resourcemanager.application-timeouts.monitor.interval-ms":"3000","mapreduce.map.output.compress.codec":"org.apache.hadoop.io.compress.SnappyCodec","mapreduce.map.speculative":"true","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.hdfs-hash-file":"/runc-root/image-tag-to-hash","mapreduce.job.speculative.retry-after-speculate":"15000","yarn.federation.failover.random.order":"false","yarn.nodemanager.linux-container-executor.cgroups.mount":"false","yarn.app.mapreduce.am.container.log.backups":"0","yarn.app.mapreduce.am.log.level":"INFO","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin":"org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.runtime.runc.ImageTagToManifestPlugin","io.bytes.per.checksum":"512","mapreduce.job.reduce.slowstart.completedmaps":"0.05","yarn.timeline-service.http-authentication.type":"simple","hadoop.security.group.mapping.ldap.search.attr.group.name":"cn","yarn.nodemanager.resource-plugins.fpga.allowed-fpga-devices":"auto","yarn.timeline-service.client.internal-timers-ttl-secs":"420","io.compression.codec.zstd.buffersize":"0","fs.s3a.select.output.csv.quote.character":"\"","hadoop.http.logs.enabled":"true","fs.s3a.block.size":"32M","yarn.sharedcache.client-server.address":"0.0.0.0:8045","yarn.nodemanager.logaggregation.threadpool-size-max":"100","yarn.resourcemanager.hostname":"0.0.0.0","ipc.callqueue.overflow.trigger.failover":"false","yarn.resourcemanager.delegation.key.update-interval":"86400000","mapreduce.reduce.shuffle.fetch.retry.enabled":"${yarn.nodemanager.recovery.enabled}","mapreduce.map.memory.mb":"3072","mapreduce.task.skip.start.attempts":"2","fs.AbstractFileSystem.hdfs.impl":"org.apache.hadoop.fs.Hdfs","yarn.nodemanager.disk-health-checker.enable":"true","fs.s3a.select.output.csv.quote.fields":"always","ipc.client.tcpnodelay":"true","ipc.client.rpc-timeout.ms":"120000","yarn.nodemanager.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","yarn.resourcemanager.delegation-token-renewer.thread-retry-max-attempts":"*********(redacted)","ipc.client.low-latency":"false","yarn.scheduler.skip.node.multiplier":"2","mapreduce.input.lineinputformat.linespermap":"1","yarn.router.interceptor.user.threadpool-size":"5","ipc.client.connect.max.retries.on.timeouts":"5","yarn.timeline-service.leveldb-timeline-store.read-cache-size":"104857600","fs.AbstractFileSystem.har.impl":"org.apache.hadoop.fs.HarFs","mapreduce.job.split.metainfo.maxsize":"10000000","yarn.am.liveness-monitor.expiry-interval-ms":"900000","yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs":"*********(redacted)","yarn.timeline-service.entity-group-fs-store.app-cache-size":"10","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-timeout-interval-secs":"360","fs.s3a.socket.recv.buffer":"8192","ipc.backoff.enable":"false","rpc.metrics.timeunit":"MILLISECONDS","mapreduce.output.fs.optimized.committer.enabled":"true","yarn.resourcemanager.resource-tracker.address":"${yarn.resourcemanager.hostname}:8031","yarn.nodemanager.node-labels.provider.fetch-timeout-ms":"1200000","mapreduce.job.heap.memory-mb.ratio":"0.8","yarn.resourcemanager.leveldb-state-store.compaction-interval-secs":"3600","yarn.resourcemanager.webapp.rest-csrf.custom-header":"X-XSRF-Header","yarn.nodemanager.pluggable-device-framework.enabled":"false","yarn.scheduler.configuration.fs.path":"file://${hadoop.tmp.dir}/yarn/system/schedconf","dfs.datanode.max.transfer.threads":"4096","mapreduce.client.output.filter":"FAILED","hadoop.http.filter.initializers":"org.apache.hadoop.security.HttpCrossOriginFilterInitializer","mapreduce.reduce.memory.mb":"6144","mapreduce.admin.user.env":"LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native:/usr/lib/hadoop-lzo/lib/native","yarn.timeline-service.hostname":"0.0.0.0","file.replication":"1","yarn.nodemanager.container-metrics.unregister-delay-ms":"10000","yarn.nodemanager.container-metrics.period-ms":"-1","mapreduce.fileoutputcommitter.task.cleanup.enabled":"false","hadoop.proxyuser.oozie.hosts":"*","yarn.nodemanager.log.retain-seconds":"10800","yarn.timeline-service.entity-group-fs-store.cleaner-interval-seconds":"3600","ipc.[port_number].callqueue.impl":"java.util.concurrent.LinkedBlockingQueue","yarn.resourcemanager.keytab":"/etc/krb5.keytab","hadoop.security.group.mapping.providers.combined":"true","mapreduce.reduce.merge.inmem.threshold":"1000","yarn.timeline-service.recovery.enabled":"false","fs.azure.saskey.usecontainersaskeyforallaccess":"true","yarn.sharedcache.nm.uploader.thread-count":"20","mapreduce.fileoutputcommitter.cleanup-failures.ignored.emr_internal_use_only.EmrFileSystem":"true","yarn.resourcemanager.nodemanager-graceful-decommission-timeout-secs":"3600","ipc.[port_number].weighted-cost.lockfree":"1","mapreduce.shuffle.ssl.enabled":"false","yarn.timeline-service.hbase.coprocessor.app-final-value-retention-milliseconds":"259200000","mapreduce.jvm.add-opens-as-default":"true","yarn.nodemanager.opportunistic-containers-max-queue-length":"0","yarn.resourcemanager.state-store.max-completed-applications":"${yarn.resourcemanager.max-completed-applications}","mapreduce.job.speculative.minimum-allowed-tasks":"10","fs.s3a.aws.credentials.provider":"software.amazon.awssdk.auth.credentials.DefaultCredentialsProvider","yarn.log-aggregation.retain-seconds":"-1","yarn.router.interceptor.allow-partial-result.enable":"false","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb":"0","mapreduce.jobhistory.max-age-ms":"604800000","hadoop.http.cross-origin.allowed-methods":"GET,POST,HEAD","mapreduce.task.ping-for-liveliness-check.enabled":"false","yarn.resourcemanager.opportunistic-container-allocation.enabled":"false","fs.azure.enable.readahead":"true","mapreduce.jobhistory.webapp.address":"0.0.0.0:19888","hadoop.system.tags":"YARN,HDFS,NAMENODE,DATANODE,REQUIRED,SECURITY,KERBEROS,PERFORMANCE,CLIENT\n      ,SERVER,DEBUG,DEPRECATED,COMMON,OPTIONAL","yarn.federation.gpg.webapp.cross-origin.enabled":"false","yarn.log-aggregation.file-controller.TFile.class":"org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController","yarn.client.nodemanager-connect.max-wait-ms":"180000","yarn.resourcemanager.webapp.address":"${yarn.resourcemanager.hostname}:8088","mapreduce.jobhistory.recovery.enable":"false","mapreduce.reduce.shuffle.parallelcopies":"20","fs.AbstractFileSystem.webhdfs.impl":"org.apache.hadoop.fs.WebHdfs","fs.trash.interval":"0","yarn.app.mapreduce.client.max-retries":"3","hadoop.security.authentication":"simple","mapreduce.task.profile.reduce.params":"${mapreduce.task.profile.params}","dfs.datanode.du.reserved":"536870912","yarn.app.mapreduce.am.resource.mb":"6144","mapreduce.input.fileinputformat.list-status.num-threads":"1","io.compression.codec.lzo.class":"com.hadoop.compression.lzo.LzoCodec","yarn.nodemanager.container-executor.class":"org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor","yarn.router.interceptor.user-thread-pool.minimum-pool-size":"5","io.mapfile.bloom.size":"1048576","yarn.timeline-service.ttl-ms":"604800000","yarn.resourcemanager.nm-container-queuing.min-queue-length":"5","yarn.nodemanager.resource.cpu-vcores":"-1","yarn.federation.state-store.clean-up-retry-sleep-time":"1s","mapreduce.job.reduces":"7","fs.s3a.multipart.size":"64M","mapreduce.fileoutputcommitter.algorithm.version.emr_internal_use_only.EmrFileSystem":"2","fs.s3a.select.input.csv.comment.marker":"#","yarn.scheduler.minimum-allocation-vcores":"1","mapreduce.job.speculative.speculative-cap-total-tasks":"0.01","hadoop.ssl.client.conf":"ssl-client.xml","mapreduce.job.queuename":"default","mapreduce.job.encrypted-intermediate-data-key-size-bits":"128","fs.iostatistics.thread.level.enabled":"true","ipc.[port_number].weighted-cost.response":"1","yarn.nodemanager.webapp.xfs-filter.xframe-options":"SAMEORIGIN","ha.health-monitor.sleep-after-disconnect.ms":"1000","yarn.app.mapreduce.shuffle.log.limit.kb":"0","hadoop.security.group.mapping":"org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback","yarn.client.application-client-protocol.poll-timeout-ms":"-1","mapreduce.jobhistory.jhist.format":"binary","mapreduce.task.stuck.timeout-ms":"600000","yarn.resourcemanager.application.max-tag.length":"100","yarn.resourcemanager.ha.enabled":"false","dfs.client.ignore.namenode.default.kms.uri":"false","hadoop.http.staticuser.user":"dr.who","mapreduce.task.exit.timeout.check-interval-ms":"20000","mapreduce.jobhistory.intermediate-user-done-dir.permissions":"770","mapreduce.task.exit.timeout":"60000","yarn.nodemanager.linux-container-executor.resources-handler.class":"org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler","mapreduce.reduce.shuffle.memory.limit.percent":"0.25","yarn.resourcemanager.reservation-system.enable":"false","mapreduce.map.output.compress":"true","ha.zookeeper.acl":"world:anyone:rwcda","yarn.federation.state-store.sql.conn-time-out":"10s","hadoop.proxyuser.presto.groups":"*","io.compression.codec.lz4.buffersize":"262144","ipc.server.max.connections":"0","yarn.nodemanager.runtime.linux.docker.default-container-network":"host","yarn.router.webapp.address":"0.0.0.0:8089","yarn.scheduler.maximum-allocation-mb":"8192","yarn.resourcemanager.scheduler.monitor.policies":"org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy","yarn.sharedcache.cleaner.period-mins":"1440","ipc.client.async.calls.max":"100","yarn.nodemanager.resource-plugins.gpu.docker-plugin.nvidia-docker-v1.endpoint":"http://localhost:3476/v1.0/docker/cli","yarn.app.mapreduce.am.container.log.limit.kb":"0","ipc.client.connect.retry.interval":"1000","yarn.timeline-service.http-cross-origin.enabled":"false","fs.wasbs.impl":"org.apache.hadoop.fs.azure.NativeAzureFileSystem$Secure","yarn.resourcemanager.nodemanagers.heartbeat-interval-max-ms":"1000","hadoop.http.jmx.nan-filter.enabled":"false","yarn.router.scheduled.executor.threads":"1","hadoop.proxyuser.httpfs.groups":"*","yarn.federation.subcluster-resolver.class":"org.apache.hadoop.yarn.server.federation.resolver.DefaultSubClusterResolverImpl","yarn.resourcemanager.zk-state-store.parent-path":"/rmstore","fs.s3a.select.input.csv.field.delimiter":",","yarn.nodemanager.least-load-policy-selector.multiplier":"50000","mapreduce.jobhistory.cleaner.enable":"true","yarn.timeline-service.client.fd-flush-interval-secs":"10","hadoop.security.kms.client.encrypted.key.cache.expiry":"43200000","hadoop.proxyuser.httpfs.hosts":"*","yarn.client.nodemanager-client-async.thread-pool-max-size":"500","mapreduce.map.maxattempts":"4","yarn.resourcemanager.nm-container-queuing.sorting-nodes-interval-ms":"1000","fs.s3a.committer.staging.tmp.path":"tmp/staging","yarn.nodemanager.sleep-delay-before-sigkill.ms":"250","yarn.resourcemanager.nm-container-queuing.min-queue-wait-time-ms":"10","mapreduce.job.end-notification.retry.attempts":"0","yarn.nodemanager.resource.count-logical-processors-as-cores":"false","mapred.output.direct.NativeS3FileSystem":"true","hadoop.registry.zk.root":"/registry","yarn.federation.state-store.sql.pool-name":"YARN-Federation-DataBasePool","adl.feature.ownerandgroup.enableupn":"false","yarn.resourcemanager.zk-max-znode-size.bytes":"1048576","mapreduce.job.reduce.shuffle.consumer.plugin.class":"org.apache.hadoop.mapreduce.task.reduce.Shuffle","yarn.resourcemanager.delayed.delegation-token.removal-interval-ms":"*********(redacted)","yarn.nodemanager.localizer.cache.target-size-mb":"10240","fs.s3a.committer.staging.conflict-mode":"append","mapreduce.client.libjars.wildcard":"true","fs.s3a.committer.staging.unique-filenames":"true","yarn.nodemanager.node-attributes.provider.fetch-timeout-ms":"1200000","yarn.nodemanager.amrmproxy.wait.uam-register.done":"false","fs.s3a.list.version":"2","ftp.client-write-packet-size":"65536","yarn.federation.gpg.policy.generator.load-based.pending.minimum":"100","ipc.[port_number].weighted-cost.lockexclusive":"100","fs.AbstractFileSystem.adl.impl":"org.apache.hadoop.fs.adl.Adl","hadoop.proxyuser.hive.hosts":"*","yarn.nodemanager.container-log-monitor.enable":"false","hadoop.security.key.default.cipher":"AES/CTR/NoPadding","yarn.client.failover-retries":"0","fs.s3a.multipart.purge.age":"24h","mapreduce.job.local-fs.single-disk-limit.check.interval-ms":"5000","net.topology.node.switch.mapping.impl":"org.apache.hadoop.net.ScriptBasedMapping","yarn.nodemanager.amrmproxy.address":"0.0.0.0:8049","ipc.server.listen.queue.size":"256","ipc.[port_number].decay-scheduler.period-ms":"5000","yarn.nodemanager.container-localizer.java.opts.add-exports-as-default":"true","yarn.nodemanager.runtime.linux.runc.image-tag-to-manifest-plugin.cache-refresh-interval-secs":"60","map.sort.class":"org.apache.hadoop.util.QuickSort","yarn.federation.state-store.max-applications":"1000","fs.viewfs.rename.strategy":"SAME_MOUNTPOINT","hadoop.security.kms.client.authentication.retry-count":"1","fs.permissions.umask-mode":"022","fs.s3a.assumed.role.credentials.provider":"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider","yarn.nodemanager.runtime.linux.runc.privileged-containers.allowed":"false","ipc.server.handler.queue.size":"100","yarn.nodemanager.vmem-check-enabled":"true","yarn.nodemanager.numa-awareness.enabled":"false","yarn.nodemanager.recovery.compaction-interval-secs":"3600","yarn.app.mapreduce.client-am.ipc.max-retries":"3","yarn.resourcemanager.system-metrics-publisher.timeline-server-v1.interval-seconds":"60","yarn.federation.registry.base-dir":"yarnfederation/","yarn.nodemanager.health-checker.run-before-startup":"false","spark.app.id":"spark-application-1736633168473","mapreduce.job.max.map":"-1","mapreduce.job.local-fs.single-disk-limit.bytes":"-1","mapreduce.shuffle.pathcache.concurrency-level":"16","mapreduce.job.ubertask.maxreduces":"1","mapreduce.shuffle.pathcache.max-weight":"10485760","hadoop.security.kms.client.encrypted.key.cache.size":"500","hadoop.security.java.secure.random.algorithm":"SHA1PRNG","ha.failover-controller.cli-check.rpc-timeout.ms":"20000","mapreduce.jobhistory.jobname.limit":"50","fs.s3a.select.input.compression":"none","mapreduce.application.classpath":"\n    $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,\n    $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*,\n    /usr/lib/hadoop-lzo/lib/*,\n    /usr/share/aws/emr/emrfs/conf,\n    /usr/share/aws/emr/emrfs/lib/*,\n    /usr/share/aws/emr/emrfs/auxlib/*,\n    /usr/share/aws/emr/lib/*,\n    /usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar,\n    /usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar,\n    /usr/share/aws/emr/cloudwatch-sink/lib/*,\n    /usr/share/aws/aws-java-sdk/*\n  ","yarn.client.nodemanager-connect.retry-interval-ms":"10000","ipc.[port_number].scheduler.priority.levels":"4","yarn.timeline-service.state-store-class":"org.apache.hadoop.yarn.server.timeline.recovery.LeveldbTimelineStateStore","yarn.nodemanager.env-whitelist":"JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ","yarn.federation.state-store.clean-up-retry-count":"1","yarn.sharedcache.nested-level":"3","yarn.timeline-service.webapp.rest-csrf.methods-to-ignore":"GET,OPTIONS,HEAD","fs.azure.user.agent.prefix":"unknown","yarn.resourcemanager.zk-delegation-token-node.split-index":"*********(redacted)","yarn.nodemanager.numa-awareness.read-topology":"false","yarn.nodemanager.webapp.address":"${yarn.nodemanager.hostname}:8042","rpc.metrics.quantile.enable":"false","yarn.registry.class":"org.apache.hadoop.registry.client.impl.FSRegistryOperationsService","mapreduce.jobhistory.admin.acl":"*","yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size":"10","yarn.scheduler.queue-placement-rules":"user-group","hadoop.http.authentication.kerberos.keytab":"${user.home}/hadoop.keytab","yarn.resourcemanager.recovery.enabled":"false","fs.s3a.select.input.csv.header":"none","yarn.federation.gpg.policy.generator.load-based.scaling":"LINEAR","yarn.nodemanager.runtime.linux.runc.hdfs-manifest-to-resources-plugin.stat-cache-size":"500","yarn.timeline-service.webapp.rest-csrf.enabled":"false","dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold":"10737418240","yarn.nodemanager.disk-health-checker.min-free-space-per-disk-watermark-high-mb":"0"},"System Properties":{"java.io.tmpdir":"/tmp","RDS_TRUSTSTORE_URL":"file:/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","sun.cpu.endian":"little","java.specification.maintenance.version":"1","java.specification.version":"17","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Amazon.com Inc.","java.vm.specification.version":"17","user.home":"/home/hadoop","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-17-amazon-corretto.x86_64/lib","user.dir":"/tmp","java.library.path":"/usr/lib/hadoop/lib/native:/usr/lib/hadoop-lzo/lib/native:/docker/usr/lib/hadoop/lib/native:/docker/usr/lib/hadoop-lzo/lib/native:/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib","os.arch":"amd64","java.vm.version":"17.0.13+11-LTS","java.runtime.version":"17.0.13+11-LTS","java.vm.info":"mixed mode, sharing","java.runtime.name":"OpenJDK Runtime Environment","java.version.date":"2024-10-15","file.separator":"/","java.class.version":"61.0","java.specification.name":"Java Platform API Specification","file.encoding":"ANSI_X3.4-1968","user.timezone":"GMT","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","java.vm.compressedOopsMode":"Zero based","os.version":"5.10.227-219.884.amzn2.x86_64","native.encoding":"ANSI_X3.4-1968","java.vm.specification.vendor":"Oracle Corporation","javax.net.ssl.trustStore":"/opt/amazon/certs/InternalAndExternalAndAWSTrustStore.jks","user.country":"US","sun.jnu.encoding":"ANSI_X3.4-1968","user.language":"en","java.vendor.version":"Corretto-17.0.13.11.1","RDS_ROOT_CERT_PATH":"/opt/amazon/certs/rds-combined-ca-bundle.pem","REDSHIFT_ROOT_CERT_PATH":"/opt/amazon/certs/redshift-ssl-ca-cert.pem","java.vendor.url":"https://aws.amazon.com/corretto/","javax.net.ssl.trustStoreType":"JKS","log4j.configurationFile":"/tmp/glue-job-286077850716913077/glue-14643565023718328655log4j2.properties","os.name":"Linux","java.vm.vendor":"Amazon.com Inc.","jdk.debug":"release","java.vendor.url.bug":"https://github.com/corretto/corretto-17/issues/","user.name":"hadoop","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"*********(redacted)","java.home":"/usr/lib/jvm/java-17-amazon-corretto.x86_64","javax.net.ssl.trustStorePassword":"*********(redacted)","java.version":"17.0.13","sun.io.unicode.encoding":"UnicodeLittle"},"Metrics Properties":{"*.source.system.class":"org.apache.spark.metrics.source.SystemMetricsSource","driver.source.glue.jobPerformance.class":"org.apache.spark.metrics.source.PerformanceMetricsSource","*.source.s3.class":"org.apache.spark.metrics.source.S3FileSystemSource","*.sink.servlet.path":"/metrics/json","*.sink.GlueCloudwatch.proxyPort":"-1","driver.source.throughput.class":"org.apache.spark.metrics.source.ThroughputMetricsSource","driver.source.aggregate.class":"org.apache.spark.metrics.source.AggregateMetricsSource","*.sink.GlueCloudwatch.glueVersion":"5.0","*.sink.GlueCloudwatch.legacyMetrics":"true","*.sink.servlet.class":"org.apache.spark.metrics.sink.MetricsServlet","driver.source.glue.jobPerformance.skewnessFactor":"5","driver.source.glue.resourceUtilization.class":"org.apache.spark.metrics.source.ResourceUtilizationMetricsSource","*.sink.GlueCloudwatch.namespace":"Glue","*.sink.GlueCloudwatch.class":"org.apache.spark.metrics.sink.GlueCloudwatchSink","*.sink.GlueCloudwatch.accountId":"825765421264","*.sink.GlueCloudwatch.proxyHost":"null","*.source.jvm.class":"org.apache.spark.metrics.source.JvmSource","applications.sink.servlet.path":"/metrics/applications/json","master.sink.servlet.path":"/metrics/master/json","*.sink.GlueCloudwatch.jobName":"de-on-youtube-parquet-analystics","*.sink.GlueCloudwatch.jobRunId":"jr_4a19f832628913910d9c544e5b10d7c2f8b45f2669b5ee4537c6d875d1769971","*.source.glue.verticalScaling.class":"org.apache.spark.metrics.source.VerticalScalingMetricsSource"},"Classpath Entries":{"/usr/lib/hadoop/hadoop-annotations.jar":"System Classpath","/usr/lib/hadoop/hadoop-kafka-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/aircompressor-0.27.jar":"System Classpath","/usr/lib/spark/jars/arrow-format-12.0.1.jar":"System Classpath","/usr/lib/spark/jars/RoaringBitmap-0.9.45.jar":"System Classpath","/usr/lib/spark/jars/spark-ganglia-lgpl_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/spark-acl-1.0.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-aws-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/hadoop/hadoop-client-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/livy/rsc-jars/livy-rsc-0.7.1-incubating.jar":"System Classpath","/usr/lib/spark/jars/netty-all-4.1.100.Final.jar":"System Classpath","/usr/lib/spark/jars/jackson-core-asl-1.9.13.jar":"System Classpath","/usr/lib/hadoop/hadoop-resourceestimator-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jackson-datatype-jsr310-2.15.2.jar":"System Classpath","/usr/lib/spark/jars/hadoop-client-runtime-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/netty-buffer-4.1.100.Final.jar":"System Classpath","/usr/lib/hadoop/hadoop-azure-3.4.0-amzn-1.jar":"System Classpath","/usr/share/aws/redshift/spark-redshift/lib/spark-redshift_2.12-6.3.0-spark_3.5.jar":"System Classpath","/usr/lib/spark/jars/spark-network-shuffle_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/livy/rsc-jars/livy-thriftserver-session-0.7.1-incubating.jar":"System Classpath","/usr/lib/hadoop/hadoop-annotations-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/aopalliance-repackaged-2.6.1.jar":"System Classpath","/usr/lib/spark/jars/metrics-jmx-4.2.19.jar":"System Classpath","/usr/share/aws/iceberg/lib/iceberg-emr-common.jar":"System Classpath","/usr/share/aws/aws-glue-shuffle/AWSGlueShuffle-5.0.0.jar":"System Classpath","/usr/lib/spark/jars/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar":"System Classpath","/usr/lib/spark/jars/zookeeper-jute-3.9.1.jar":"System Classpath","/usr/lib/hadoop/hadoop-gridmix.jar":"System Classpath","/usr/lib/spark/jars/avro-mapred-1.11.2.jar":"System Classpath","/usr/share/java/Hive-JSON-Serde/json-udf.jar":"System Classpath","/usr/lib/spark/jars/osgi-resource-locator-1.0.3.jar":"System Classpath","/usr/lib/spark/jars/hive-storage-api-2.8.1.jar":"System Classpath","/usr/lib/spark/jars/commons-math3-3.6.1.jar":"System Classpath","/usr/lib/spark/jars/libfb303-0.9.3.jar":"System Classpath","/usr/lib/spark/jars/hive-llap-common-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/netty-transport-classes-epoll-4.1.100.Final.jar":"System Classpath","/usr/lib/spark/jars/flatbuffers-java-1.12.0.jar":"System Classpath","/usr/lib/spark/jars/datanucleus-rdbms-4.1.19.jar":"System Classpath","/usr/lib/spark/jars/jersey-hk2-2.40.jar":"System Classpath","/tmp/glue-job-286077850716913077/aws_glue_connectors/marketplace/*":"System Classpath","/usr/lib/hadoop/hadoop-azure.jar":"System Classpath","/usr/lib/spark/jars/spark-launcher_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jakarta.inject-2.6.1.jar":"System Classpath","/docker/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar":"System Classpath","/usr/lib/spark/jars/animal-sniffer-annotations-1.23.jar":"System Classpath","/usr/lib/spark/jars/jsr305-3.0.0.jar":"System Classpath","/usr/lib/spark/jars/HikariCP-2.5.1.jar":"System Classpath","/usr/lib/spark/jars/jdo-api-3.0.1.jar":"System Classpath","/usr/lib/spark/jars/pickle-1.3.jar":"System Classpath","/usr/lib/spark/jars/JTransforms-3.1.jar":"System Classpath","/usr/lib/spark/jars/xbean-asm9-shaded-4.23.jar":"System Classpath","/usr/lib/hadoop/hadoop-resourceestimator.jar":"System Classpath","/usr/lib/spark/jars/spark-tags_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar":"System Classpath","/usr/lib/spark/jars/jersey-common-2.40.jar":"System Classpath","/usr/lib/spark/jars/libthrift-0.12.0.jar":"System Classpath","/tmp/glue-job-286077850716913077/*":"System Classpath","/usr/lib/spark/jars/httpcore-4.4.13.jar":"System Classpath","/usr/lib/spark/jars/avro-ipc-1.11.2.jar":"System Classpath","/usr/lib/spark/jars/netty-codec-socks-4.1.100.Final.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/jsr305-3.0.2.jar":"System Classpath","/usr/lib/spark/jars/jpam-1.1.jar":"System Classpath","/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar":"System Classpath","/usr/lib/spark/jars/kryo-shaded-4.0.2.jar":"System Classpath","/usr/lib/spark/jars/scala-collection-compat_2.12-2.7.0.jar":"System Classpath","/usr/lib/spark/jars/scala-compiler-2.12.18.jar":"System Classpath","/usr/lib/spark/jars/netty-common-4.1.100.Final.jar":"System Classpath","/usr/lib/spark/jars/py4j-0.10.9.7.jar":"System Classpath","/usr/lib/spark/jars/arrow-memory-netty-12.0.1.jar":"System Classpath","/usr/lib/spark/jars/curator-client-2.13.0.jar":"System Classpath","/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar":"System Classpath","/usr/lib/spark/jars/chill-java-0.10.0.jar":"System Classpath","/usr/lib/livy/repl_2.12-jars/livy-core_2.12-0.7.1-incubating.jar":"System Classpath","/usr/lib/spark/jars/curator-framework-2.13.0.jar":"System Classpath","/usr/share/aws/emr/security/conf":"System Classpath","/usr/share/aws/emr/emrfs/lib/kryo-shaded-4.0.2.jar":"System Classpath","/usr/lib/spark/jars/istack-commons-runtime-3.0.8.jar":"System Classpath","/usr/lib/spark/jars/parquet-encoding-1.13.1-amzn-3.jar":"System Classpath","/usr/lib/spark/jars/hk2-locator-2.6.1.jar":"System Classpath","/usr/lib/spark/jars/commons-lang-2.6.jar":"System Classpath","/usr/lib/hadoop/hadoop-federation-balance-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/hadoop/hadoop-auth-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/commons-collections4-4.4.jar":"System Classpath","/usr/share/aws/emr/goodies/lib/emr-serverless-spark-goodies.jar":"System Classpath","/usr/lib/spark/jars/curator-recipes-2.13.0.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/javax.inject-1.jar":"System Classpath","/usr/lib/spark/jars/jersey-server-2.40.jar":"System Classpath","/usr/lib/spark/jars/jackson-dataformat-yaml-2.15.2.jar":"System Classpath","/usr/lib/spark/jars/jackson-annotations-2.15.2.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/emrfs-hadoop-assembly-2.66.0.jar":"System Classpath","/usr/share/aws/iceberg/lib/iceberg-spark3-runtime.jar":"System Classpath","/usr/lib/spark/jars/metrics-jvm-4.2.19.jar":"System Classpath","/usr/lib/spark/jars/ivy-2.5.1.jar":"System Classpath","/usr/lib/spark/jars/httpclient-4.5.13.jar":"System Classpath","/usr/lib/spark/jars/jersey-container-servlet-core-2.40.jar":"System Classpath","/usr/lib/spark/jars/parquet-hadoop-1.13.1-amzn-3.jar":"System Classpath","/usr/lib/spark/jars/jackson-databind-2.15.2.jar":"System Classpath","/usr/lib/spark/jars/paranamer-2.8.jar":"System Classpath","/usr/share/java/Hive-JSON-Serde/json-udf-1.3.8.jar":"System Classpath","/usr/lib/hadoop/hadoop-rumen-3.4.0-amzn-1.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/AssumeRoleAWSCredentialsProvider-1.1-SNAPSHOT.jar":"System Classpath","/usr/lib/spark/jars/rocksdbjni-8.3.2.jar":"System Classpath","/usr/lib/spark/jars/snappy-java-1.1.10.5.jar":"System Classpath","/usr/share/aws/hmclient/lib/aws-glue-datacatalog-client-common-4.2.0.jar":"System Classpath","/usr/lib/spark/jars/spark-network-common_2.12-3.5.2-amzn-1.jar":"System Classpath","/docker/usr/share/aws/sagemaker-spark-sdk/lib/sagemaker-spark-sdk.jar":"System Classpath","/usr/share/aws/iceberg/lib/iceberg-hive-runtime-1.6.1-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jakarta.annotation-api-1.3.5.jar":"System Classpath","/usr/lib/spark/jars/jersey-client-2.40.jar":"System Classpath","/usr/lib/spark/jars/commons-collections-3.2.2.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/findbugs-annotations-3.0.1.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-OpenSearch-1.0.jar":"System Classpath","/usr/lib/spark/jars/commons-logging-1.1.3.jar":"System Classpath","/usr/lib/spark/jars/jackson-module-scala_2.12-2.15.2.jar":"System Classpath","/usr/lib/spark/jars/commons-compiler-3.1.9.jar":"System Classpath","/usr/share/aws/glue-pii-dependencies/lib/stanford-corenlp-3.6.0-models.jar":"System Classpath","/usr/lib/spark/jars/hive-metastore-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/avro-1.11.2.jar":"System Classpath","/usr/lib/spark/jars/chill_2.12-0.10.0.jar":"System Classpath","/usr/lib/spark/jars/volcano-client-6.7.2.jar":"System Classpath","/usr/lib/hadoop/hadoop-client.jar":"System Classpath","/usr/lib/spark/jars/spark-sql_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/datasketches-java-3.3.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-shaded-protobuf_3_21-1.2.0.jar":"System Classpath","/usr/lib/spark/jars/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar":"System Classpath","/usr/lib/spark/jars/spark-hive-thriftserver_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jcl-over-slf4j-2.0.7.jar":"System Classpath","/usr/lib/hadoop/hadoop-dynamometer-workload.jar":"System Classpath","/usr/lib/spark/jars/emr-serverless-spark-goodies.jar":"System Classpath","/usr/lib/spark/jars/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar":"System Classpath","/usr/share/aws/redshift/jdbc/aws-secretsmanager-jdbc-1.0.12.jar":"System Classpath","/usr/lib/spark/jars/hive-shims-common-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/hadoop-lzo/lib/hadoop-lzo-0.4.19.jar":"System Classpath","/usr/share/aws/redshift/spark-redshift/lib/spark-redshift.jar":"System Classpath","/usr/lib/spark/jars/arpack-3.0.3.jar":"System Classpath","/usr/lib/spark/jars/xz-1.9.jar":"System Classpath","/usr/lib/spark/jars/commons-lang3-3.12.0.jar":"System Classpath","/usr/lib/spark/jars/janino-3.1.9.jar":"System Classpath","/usr/lib/spark/jars/javax.jdo-3.2.0-m3.jar":"System Classpath","/usr/lib/spark/jars/grpc-protobuf-lite-1.56.0.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/minlog-1.3.0.jar":"System Classpath","/usr/share/aws/emr/security/lib/*":"System Classpath","/usr/lib/spark/jars/snakeyaml-engine-2.6.jar":"System Classpath","/usr/lib/spark/jars/jta-1.1.jar":"System Classpath","/usr/lib/hadoop/hadoop-azure-datalake.jar":"System Classpath","/usr/lib/spark/jars/spark-core_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jackson-core-2.15.2.jar":"System Classpath","/usr/lib/spark/jars/json-1.8.jar":"System Classpath","/usr/lib/spark/jars/disruptor-3.3.7.jar":"System Classpath","/usr/lib/spark/jars/orc-mapreduce-1.9.4-shaded-protobuf.jar":"System Classpath","/usr/lib/spark/jars/annotations-17.0.0.jar":"System Classpath","/usr/share/aws/redshift/jdbc/AwsSecretsManagerJDBC.jar":"System Classpath","/usr/lib/spark/jars/stream-2.9.6.jar":"System Classpath","/usr/lib/hadoop/hadoop-dynamometer-blockgen.jar":"System Classpath","/usr/share/aws/redshift/jdbc/redshift-jdbc42-2.1.0.29.jar":"System Classpath","/usr/lib/spark/jars/scala-xml_2.12-2.1.0.jar":"System Classpath","/usr/lib/spark/jars/log4j-slf4j2-impl-2.20.0.jar":"System Classpath","/usr/lib/spark/jars/emr-serverless-goodies-common.jar":"System Classpath","/usr/lib/hadoop/hadoop-archive-logs.jar":"System Classpath","/usr/lib/spark/jars/hive-beeline-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/aggdesigner-algorithm-6.0.jar":"System Classpath","/usr/lib/spark/jars/volcano-model-v1beta1-6.7.2.jar":"System Classpath","/usr/lib/spark/jars/spark-mllib-local_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/hadoop/hadoop-distcp-3.4.0-amzn-1.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-AzureSQL-1.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-kms-3.4.0-amzn-1.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-PostgreSQL-1.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-dynamometer-infra-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/hadoop/hadoop-sls.jar":"System Classpath","/usr/lib/hadoop/hadoop-common-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/antlr4-runtime-4.9.3.jar":"System Classpath","/usr/lib/spark/jars/remotetea-oncrpc-1.1.2.jar":"System Classpath","/usr/share/aws/iceberg/lib/iceberg-flink-runtime.jar":"System Classpath","/usr/lib/spark/jars/spark-kvstore_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/spark-mllib_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/spark-hive_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jline-2.14.6.jar":"System Classpath","/usr/lib/spark/jars/json4s-ast_2.12-3.7.0-M11.jar":"System Classpath","/usr/lib/spark/jars/activation-1.1.1.jar":"System Classpath","/usr/lib/spark/jars/spark-graphx_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/hive-shims-scheduler-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/spire_2.12-0.17.0.jar":"System Classpath","/usr/lib/spark/jars/commons-text-1.10.0.jar":"System Classpath","/usr/lib/spark/jars/jetty-rewrite-9.3.27.v20190418.jar":"System Classpath","/usr/lib/hadoop/hadoop-kafka.jar":"System Classpath","/usr/lib/spark/jars/hive-serde-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/arrow-vector-12.0.1.jar":"System Classpath","/tmp/glue-job-286077850716913077/jars/t2hVEI-aws-glue-di-package-5.0.299.jar":"System Classpath","/usr/lib/spark/jars/leveldbjni-all-1.8.jar":"System Classpath","/usr/lib/hadoop/hadoop-dynamometer-infra.jar":"System Classpath","/usr/lib/spark/jars/gmetric4j-1.0.10.jar":"System Classpath","/usr/lib/hadoop/hadoop-rumen.jar":"System Classpath","/usr/share/aws/*":"System Classpath","/usr/lib/hadoop/hadoop-streaming.jar":"System Classpath","/usr/lib/spark/jars/univocity-parsers-2.9.1.jar":"System Classpath","/usr/lib/spark/jars/netty-codec-4.1.100.Final.jar":"System Classpath","/usr/lib/spark/jars/snakeyaml-2.1.jar":"System Classpath","/usr/lib/spark/jars/javax.servlet-api-3.1.0.jar":"System Classpath","/usr/lib/spark/jars/metrics-core-4.2.19.jar":"System Classpath","/usr/lib/spark/jars/breeze-macros_2.12-2.1.0.jar":"System Classpath","/usr/lib/spark/jars/audience-annotations-0.12.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-datajoin.jar":"System Classpath","/docker/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar":"System Classpath","/usr/share/aws/datazone-openlineage-spark/lib/DataZoneOpenLineageSpark-1.0.jar":"System Classpath","/usr/lib/spark/jars/hive-common-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/spark-repl_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/error_prone_annotations-2.1.3.jar":"System Classpath","/usr/lib/hadoop/hadoop-aliyun.jar":"System Classpath","/usr/lib/spark/jars/scala-parser-combinators_2.12-2.3.0.jar":"System Classpath","/usr/lib/spark/jars/parquet-common-1.13.1-amzn-3.jar":"System Classpath","/usr/lib/spark/jars/perfmark-api-0.26.0.jar":"System Classpath","/usr/lib/spark/jars/okio-1.15.0.jar":"System Classpath","/tmp/glue-job-286077850716913077/jars/pdhdHP-AwsGlueMLLibs.jar":"System Classpath","/usr/lib/spark/jars/spark-sql-api_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/hadoop/hadoop-gridmix-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/error_prone_annotations-2.18.0.jar":"System Classpath","/usr/share/aws/iceberg/lib/iceberg-spark-runtime-3.5_2.12-1.6.1-amzn-1.jar":"System Classpath","/usr/share/aws/aws-java-sdk-v2/aws-sdk-java-bundle-2.28.8.jar":"System Classpath","/usr/lib/spark/jars/transaction-api-1.1.jar":"System Classpath","/usr/lib/hadoop/hadoop-archive-logs-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/derby-10.14.2.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-fs2img-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/spark-common-utils_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-SQLServer-1.0.jar":"System Classpath","/usr/lib/spark/jars/json4s-jackson_2.12-3.7.0-M11.jar":"System Classpath","/usr/share/aws/emr/ddb/lib/emr-ddb-hadoop.jar":"System Classpath","/usr/lib/hadoop/hadoop-registry-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/emr-spark-goodies.jar":"System Classpath","/usr/lib/spark/jars/parquet-column-1.13.1-amzn-3.jar":"System Classpath","/usr/lib/hadoop/hadoop-azure-datalake-3.4.0-amzn-1.jar":"System Classpath","/docker/usr/share/java/Hive-JSON-Serde/hive-openx-serde.jar":"System Classpath","/usr/lib/spark/jars/grpc-protobuf-1.56.0.jar":"System Classpath","/usr/lib/spark/jars/netty-codec-http-4.1.100.Final.jar":"System Classpath","/usr/share/java/Hive-JSON-Serde/json.jar":"System Classpath","/usr/lib/spark/jars/tink-1.9.0.jar":"System Classpath","/usr/lib/spark/jars/datanucleus-core-4.1.17.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-Vertica-1.0.jar":"System Classpath","/usr/lib/spark/jars/netty-handler-4.1.100.Final.jar":"System Classpath","/usr/lib/spark/jars/minlog-1.3.0.jar":"System Classpath","/usr/lib/spark/jars/jackson-mapper-asl-1.9.13.jar":"System Classpath","/usr/lib/spark/jars/zjsonpatch-0.3.0.jar":"System Classpath","/usr/lib/spark/jars/orc-shims-1.9.4.jar":"System Classpath","/usr/lib/spark/jars/gson-2.10.1.jar":"System Classpath","/usr/lib/hadoop/hadoop-fs2img.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-BigQuery-1.0.jar":"System Classpath","/usr/lib/spark/jars/spark-fgac-iceberg_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jakarta.servlet-api-4.0.3.jar":"System Classpath","/usr/lib/spark/jars/hive-shims-0.23-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/objenesis-3.3.jar":"System Classpath","/usr/lib/spark/jars/spark-sketch_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/netty-resolver-4.1.100.Final.jar":"System Classpath","/usr/lib/hadoop/hadoop-streaming-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/hadoop/hadoop-auth.jar":"System Classpath","/docker/usr/share/aws/emr/emrfs/conf":"System Classpath","/usr/lib/spark/jars/hive-exec-2.3.9-amzn-4-core.jar":"System Classpath","/usr/lib/spark/jars/datasketches-memory-2.1.0.jar":"System Classpath","/usr/lib/spark/jars/oro-2.0.8.jar":"System Classpath","/usr/lib/hadoop/hadoop-aliyun-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/grpc-core-1.56.0.jar":"System Classpath","/usr/lib/spark/jars/scala-reflect-2.12.18.jar":"System Classpath","/tmp/glue-job-286077850716913077/python/*":"System Classpath","/usr/lib/spark/jars/log4j-1.2-api-2.20.0.jar":"System Classpath","spark://172.39.121.5:46795/files/glue-job-286077850716913077_glue_venv.zip#python_environment":"Added By User","/docker/usr/share/aws/emr/security/conf":"System Classpath","/usr/lib/hadoop/hadoop-nfs.jar":"System Classpath","/usr/lib/spark/jars/grpc-stub-1.56.0.jar":"System Classpath","/usr/lib/livy/rsc-jars/livy-api-0.7.1-incubating.jar":"System Classpath","/usr/lib/spark/jars/spark-unsafe_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/share/aws/redshift/spark-redshift/lib/spark-avro_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/cats-kernel_2.12-2.1.1.jar":"System Classpath","/usr/lib/spark/jars/joda-time-2.12.5.jar":"System Classpath","/docker/usr/share/aws/emr/emrfs/auxlib/*":"System Classpath","/usr/lib/spark/jars/commons-pool-1.5.4.jar":"System Classpath","/usr/share/aws/redshift/jdbc/aws-secretsmanager-caching-java-1.0.2.jar":"System Classpath","/usr/lib/spark/jars/bonecp-0.8.0.RELEASE.jar":"System Classpath","/usr/lib/spark/jars/netty-transport-4.1.100.Final.jar":"System Classpath","/usr/lib/spark/jars/hk2-utils-2.6.1.jar":"System Classpath","/usr/lib/spark/jars/hadoop-yarn-server-web-proxy-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar":"System Classpath","/usr/lib/hadoop/hadoop-shaded-guava-1.2.0.jar":"System Classpath","/usr/lib/spark/jars/breeze_2.12-2.1.0.jar":"System Classpath","/usr/lib/spark/jars/commons-io-2.16.1.jar":"System Classpath","/usr/lib/spark/jars/algebra_2.12-2.0.1.jar":"System Classpath","/usr/lib/spark/jars/okhttp-3.12.12.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/jmespath-java-1.12.705.jar":"System Classpath","/usr/lib/spark/jars/commons-dbcp-1.4.jar":"System Classpath","/usr/lib/hadoop/hadoop-registry.jar":"System Classpath","/usr/lib/spark/jars/spark-yarn_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jersey-container-servlet-2.40.jar":"System Classpath","/usr/lib/spark/jars/netty-codec-http2-4.1.100.Final.jar":"System Classpath","/usr/lib/hadoop/hadoop-datajoin-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/spire-macros_2.12-0.17.0.jar":"System Classpath","/usr/share/java/Hive-JSON-Serde/json-1.3.8.jar":"System Classpath","/usr/share/aws/redshift/jdbc/RedshiftJDBC.jar":"System Classpath","/usr/share/java/Hive-JSON-Serde/hive-openx-serde-1.3.8.jar":"System Classpath","/usr/lib/spark/jars/hadoop-shaded-guava-1.2.0.jar":"System Classpath","/usr/lib/spark/jars/commons-crypto-1.1.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-sls-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/JLargeArrays-1.5.jar":"System Classpath","/usr/lib/spark/jars/shims-0.9.45.jar":"System Classpath","/usr/lib/hadoop/hadoop-common.jar":"System Classpath","/usr/lib/spark/jars/grpc-netty-1.56.0.jar":"System Classpath","/usr/lib/spark/jars/commons-codec-1.16.1.jar":"System Classpath","/usr/lib/spark/jars/hive-shims-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/log4j-api-2.20.0.jar":"System Classpath","/usr/lib/spark/jars/antlr-runtime-3.5.2.jar":"System Classpath","/usr/share/aws/emr/goodies/lib/emr-hadoop-goodies.jar":"System Classpath","/usr/share/aws/emr/s3select/lib/emr-s3-select-spark-connector.jar":"System Classpath","/usr/lib/spark/jars/spark-fgac_2.12-3.5.2-amzn-1.jar":"System Classpath","/usr/share/aws/emr/emrfs/auxlib/*":"System Classpath","/usr/share/aws/aws-java-sdk/aws-java-sdk-bundle-1.12.772.jar":"System Classpath","/usr/lib/spark/jars/metrics-graphite-4.2.19.jar":"System Classpath","/usr/lib/spark/jars/spark-streaming_2.12-3.5.2-amzn-1.jar":"System Classpath","/docker/usr/lib/hadoop/hadoop-aws.jar":"System Classpath","/usr/lib/spark/jars/spire-util_2.12-0.17.0.jar":"System Classpath","/usr/lib/spark/jars/log4j-core-2.20.0.jar":"System Classpath","/docker/usr/share/aws/emr/emrfs/lib/*":"System Classpath","spark://172.39.121.5:46795/jars/pdhdHP-AwsGlueMLLibs.jar":"Added By User","/usr/share/aws/emr/emrfs/lib/bcprov-ext-jdk15on-1.66.jar":"System Classpath","/usr/lib/hadoop/hadoop-archives.jar":"System Classpath","/docker/usr/share/aws/aws-java-sdk/*":"System Classpath","/usr/share/java/Hive-JSON-Serde/json-serde-1.3.8.jar":"System Classpath","/usr/lib/hadoop/hadoop-distcp.jar":"System Classpath","/usr/lib/spark/jars/commons-cli-1.5.0.jar":"System Classpath","/usr/share/aws/emr/goodies/lib/emr-spark-goodies.jar":"System Classpath","/usr/share/aws/redshift/jdbc/AwsSecretsManagerCachingJava.jar":"System Classpath","/usr/share/aws/emr/cloudwatch-sink/lib/*":"System Classpath","/usr/lib/hadoop/hadoop-dynamometer-workload-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/datanucleus-api-jdo-4.2.4.jar":"System Classpath","/usr/lib/hadoop/hadoop-federation-balance.jar":"System Classpath","/usr/lib/spark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar":"System Classpath","/usr/lib/hadoop/hadoop-minicluster.jar":"System Classpath","/usr/lib/livy/repl_2.12-jars/livy-repl_2.12-0.7.1-incubating.jar":"System Classpath","/usr/lib/spark/jars/jaxb-runtime-2.3.2.jar":"System Classpath","/usr/lib/spark/jars/hive-service-rpc-3.1.3.jar":"System Classpath","/usr/lib/spark/jars/grpc-api-1.56.0.jar":"System Classpath","/usr/lib/spark/jars/annotations-4.1.1.4.jar":"System Classpath","/usr/lib/hadoop-lzo/lib/hadoop-lzo.jar":"System Classpath","/usr/share/aws/redshift/jdbc/RedshiftJDBC42.jar":"System Classpath","/usr/lib/spark/jars/arpack_combined_all-0.1.jar":"System Classpath","/usr/lib/spark/jars/spark-catalyst_2.12-3.5.2-amzn-1.jar":"System Classpath","/etc/hadoop/conf":"System Classpath","/usr/lib/hadoop/hadoop-kms.jar":"System Classpath","/usr/lib/hadoop/hadoop-archives-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/compress-lzf-1.1.2.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-MySQL-1.0.jar":"System Classpath","/usr/lib/spark/jars/hadoop-client-api-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/arrow-memory-core-12.0.1.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/objenesis-2.5.1.jar":"System Classpath","/usr/lib/spark/jars/spire-platform_2.12-0.17.0.jar":"System Classpath","/usr/lib/spark/jars/json4s-scalap_2.12-3.7.0-M11.jar":"System Classpath","/usr/lib/spark/jars/zookeeper-3.9.1.jar":"System Classpath","/usr/lib/spark/jars/commons-compress-1.23.0.jar":"System Classpath","/usr/lib/spark/jars/zstd-jni-1.5.5-4.jar":"System Classpath","/usr/lib/spark/jars/jakarta.validation-api-2.0.2.jar":"System Classpath","/usr/lib/spark/jars/hive-cli-2.3.9-amzn-4.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-SAPHana-1.0.jar":"System Classpath","/usr/share/aws/iceberg/lib/iceberg-flink-runtime-1.19-1.6.1-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/grpc-services-1.56.0.jar":"System Classpath","/usr/lib/spark/jars/glue-spark-goodies-2.15.0.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/animal-sniffer-annotations-1.14.jar":"System Classpath","/usr/share/aws/emr-glue-bootstrap/EMRGlueBootstrap-5.0-jar-with-dependencies.jar":"System Classpath","/usr/lib/spark/jars/javassist-3.29.2-GA.jar":"System Classpath","/usr/lib/spark/jars/netty-handler-proxy-4.1.100.Final.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-AzureCosmos-1.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-common-3.4.0-amzn-1-tests.jar":"System Classpath","/usr/lib/spark/jars/threeten-extra-1.7.1.jar":"System Classpath","/usr/share/java/Hive-JSON-Serde/json-serde.jar":"System Classpath","/usr/lib/spark/jars/blas-3.0.3.jar":"System Classpath","/usr/lib/spark/jars/netty-transport-native-unix-common-4.1.100.Final.jar":"System Classpath","/usr/lib/spark/jars/json4s-core_2.12-3.7.0-M11.jar":"System Classpath","/docker/usr/share/aws/emr/security/lib/*":"System Classpath","/usr/lib/spark/jars/lz4-java-1.8.0.jar":"System Classpath","null/jars/*":"System Classpath","/usr/share/aws/emr/emrfs/lib/checker-qual-2.5.2.jar":"System Classpath","/usr/lib/spark/jars/super-csv-2.2.0.jar":"System Classpath","/usr/lib/spark/jars/jodd-core-3.5.2.jar":"System Classpath","/usr/share/aws/iceberg/lib/iceberg-hive3-runtime.jar":"System Classpath","/usr/share/aws/hmclient/lib/aws-glue-datacatalog-hive3-client-4.2.0.jar":"System Classpath","/usr/lib/spark/jars/grpc-context-1.56.0.jar":"System Classpath","/usr/lib/hadoop/hadoop-nfs-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/proto-google-common-protos-2.17.0.jar":"System Classpath","/usr/share/aws/emr/emrfs/conf":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-Teradata-1.0.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-Oracle-1.0.jar":"System Classpath","/usr/lib/spark/jars/hk2-api-2.6.1.jar":"System Classpath","/usr/lib/hadoop/hadoop-aws.jar":"System Classpath","/tmp/glue-job-286077850716913077/extra-jars/*":"System Classpath","/usr/lib/spark/jars/parquet-jackson-1.13.1-amzn-3.jar":"System Classpath","/usr/lib/spark/jars/parquet-format-structures-1.13.1-amzn-3.jar":"System Classpath","/usr/share/aws/hmclient/lib/aws-glue-datacatalog-hive3-client.jar":"System Classpath","/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client-4.2.0.jar":"System Classpath","/usr/lib/spark/jars/hive-jdbc-2.3.9-amzn-4.jar":"System Classpath","/usr/lib/spark/jars/jakarta.ws.rs-api-2.1.6.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-Snowflake-1.0.jar":"System Classpath","/usr/lib/spark/jars/netty-transport-classes-kqueue-4.1.100.Final.jar":"System Classpath","/usr/share/aws/glue-connectors/lib/GlueSparkConnector-MongoDB-1.0.jar":"System Classpath","/usr/lib/spark/jars/ST4-4.0.4.jar":"System Classpath","/usr/lib/hadoop/hadoop-extras.jar":"System Classpath","/usr/lib/hadoop/hadoop-dynamometer-blockgen-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/opencsv-2.3.jar":"System Classpath","/usr/lib/spark/jars/stax-api-1.0.1.jar":"System Classpath","/usr/lib/spark/jars/slf4j-api-2.0.7.jar":"System Classpath","/usr/lib/spark/jars/javolution-5.5.1.jar":"System Classpath","/usr/lib/spark/jars/jul-to-slf4j-2.0.7.jar":"System Classpath","/usr/share/aws/redshift/spark-redshift/lib/spark-avro.jar":"System Classpath","/usr/lib/spark/jars/logging-interceptor-3.12.12.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/annotations-16.0.2.jar":"System Classpath","/usr/lib/spark/jars/scala-library-2.12.18.jar":"System Classpath","/docker/usr/share/aws/hmclient/lib/aws-glue-datacatalog-spark-client.jar":"System Classpath","/usr/lib/spark/jars/metrics-json-4.2.19.jar":"System Classpath","/usr/lib/spark/jars/guava-14.0.1.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/j2objc-annotations-1.1.jar":"System Classpath","/usr/share/aws/emr/emrfs/lib/aopalliance-1.0.jar":"System Classpath","/usr/lib/spark/jars/lapack-3.0.3.jar":"System Classpath","spark://172.39.121.5:46795/jars/t2hVEI-aws-glue-di-package-5.0.299.jar":"Added By User","/usr/lib/hadoop/hadoop-minicluster-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/conf":"System Classpath","/usr/lib/hadoop/hadoop-extras-3.4.0-amzn-1.jar":"System Classpath","/usr/lib/spark/jars/jakarta.xml.bind-api-2.3.2.jar":"System Classpath","/lib/*":"System Classpath","/usr/lib/spark/jars/orc-core-1.9.4-shaded-protobuf.jar":"System Classpath","/docker/usr/lib/hadoop-lzo/lib/*":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"nativespark-de-on-youtube-parquet-analystics-jr_4a19f832628913910d9c544e5b10d7c2f8b45f2669b5ee4537c6d875d1769971","App ID":"spark-application-1736633168473","Timestamp":1736633163833,"User":"hadoop","Driver Logs":{},"Driver Attributes":{}}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1736633180152,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"resolveRelation at DataSource.scala:770","Number of Tasks":1,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"mapPartitions\"}","Callsite":"resolveRelation at DataSource.scala:770","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"0\",\"name\":\"parallelize\"}","Callsite":"resolveRelation at DataSource.scala:770","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.wrapper.SparkSqlDecoratorDataSource.resolveRelation(SparkSqlDecoratorDataSource.scala:99)\ncom.amazonaws.services.glue.SparkSQLDataSource.getDynamicFrame(DataSource.scala:770)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame(DataSource.scala:95)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame$(DataSource.scala:95)\ncom.amazonaws.services.glue.AbstractSparkSQLDataSource.getDynamicFrame(DataSource.scala:693)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[0],"Properties":{"spark.rdd.scope":"{\"id\":\"2\",\"name\":\"collect\"}","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"resolveRelation at DataSource.scala:770","Number of Tasks":1,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"mapPartitions\"}","Callsite":"resolveRelation at DataSource.scala:770","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"0\",\"name\":\"parallelize\"}","Callsite":"resolveRelation at DataSource.scala:770","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.wrapper.SparkSqlDecoratorDataSource.resolveRelation(SparkSqlDecoratorDataSource.scala:99)\ncom.amazonaws.services.glue.SparkSQLDataSource.getDynamicFrame(DataSource.scala:770)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame(DataSource.scala:95)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame$(DataSource.scala:95)\ncom.amazonaws.services.glue.AbstractSparkSQLDataSource.getDynamicFrame(DataSource.scala:693)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Submission Time":1736633180197,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.rdd.scope":"{\"id\":\"2\",\"name\":\"collect\"}","resource.executor.cores":"4","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633188124,"Executor ID":"8","Executor Info":{"Host":"172.39.70.41","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633188124}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"8","Host":"172.39.70.41","Port":33737},"Maximum Memory":6253707264,"Timestamp":1736633188249,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1736633189566,"Executor ID":"8","Host":"172.39.70.41","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633190514,"Executor ID":"1","Executor Info":{"Host":"172.36.182.108","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633190514}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"1","Host":"172.36.182.108","Port":41853},"Maximum Memory":6253707264,"Timestamp":1736633190743,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633191376,"Executor ID":"9","Executor Info":{"Host":"172.38.148.117","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633191376}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"9","Host":"172.38.148.117","Port":36577},"Maximum Memory":6253707264,"Timestamp":1736633191655,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1736633189566,"Executor ID":"8","Host":"172.39.70.41","Locality":"PROCESS_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1736633192362,"Failed":false,"Killed":false,"Accumulables":[{"ID":1,"Name":"internal.metrics.executorDeserializeTime","Update":700,"Value":700,"Internal":true,"Count Failed Values":true},{"ID":2,"Name":"internal.metrics.executorDeserializeCpuTime","Update":366505008,"Value":366505008,"Internal":true,"Count Failed Values":true},{"ID":3,"Name":"internal.metrics.executorRunTime","Update":2001,"Value":2001,"Internal":true,"Count Failed Values":true},{"ID":4,"Name":"internal.metrics.executorCpuTime","Update":198577080,"Value":198577080,"Internal":true,"Count Failed Values":true},{"ID":5,"Name":"internal.metrics.resultSize","Update":2447,"Value":2447,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.jvmGCTime","Update":34,"Value":34,"Internal":true,"Count Failed Values":true},{"ID":7,"Name":"internal.metrics.resultSerializationTime","Update":5,"Value":5,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":700,"Executor Deserialize CPU Time":366505008,"Executor Run Time":2001,"Executor CPU Time":198577080,"Peak Execution Memory":0,"Result Size":2447,"JVM GC Time":34,"Result Serialization Time":5,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":0,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"resolveRelation at DataSource.scala:770","Number of Tasks":1,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1\",\"name\":\"mapPartitions\"}","Callsite":"resolveRelation at DataSource.scala:770","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":0,"Name":"ParallelCollectionRDD","Scope":"{\"id\":\"0\",\"name\":\"parallelize\"}","Callsite":"resolveRelation at DataSource.scala:770","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.wrapper.SparkSqlDecoratorDataSource.resolveRelation(SparkSqlDecoratorDataSource.scala:99)\ncom.amazonaws.services.glue.SparkSQLDataSource.getDynamicFrame(DataSource.scala:770)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame(DataSource.scala:95)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame$(DataSource.scala:95)\ncom.amazonaws.services.glue.AbstractSparkSQLDataSource.getDynamicFrame(DataSource.scala:693)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Submission Time":1736633180197,"Completion Time":1736633192378,"Accumulables":[{"ID":1,"Name":"internal.metrics.executorDeserializeTime","Value":700,"Internal":true,"Count Failed Values":true},{"ID":2,"Name":"internal.metrics.executorDeserializeCpuTime","Value":366505008,"Internal":true,"Count Failed Values":true},{"ID":3,"Name":"internal.metrics.executorRunTime","Value":2001,"Internal":true,"Count Failed Values":true},{"ID":4,"Name":"internal.metrics.executorCpuTime","Value":198577080,"Internal":true,"Count Failed Values":true},{"ID":5,"Name":"internal.metrics.resultSize","Value":2447,"Internal":true,"Count Failed Values":true},{"ID":6,"Name":"internal.metrics.jvmGCTime","Value":34,"Internal":true,"Count Failed Values":true},{"ID":7,"Name":"internal.metrics.resultSerializationTime","Value":5,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1736633192383,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633193826,"Executor ID":"3","Executor Info":{"Host":"172.36.184.148","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633193826}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"3","Host":"172.36.184.148","Port":39989},"Maximum Memory":6253707264,"Timestamp":1736633193972,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633194333,"Executor ID":"7","Executor Info":{"Host":"172.34.194.64","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633194333}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"7","Host":"172.34.194.64","Port":37451},"Maximum Memory":6253707264,"Timestamp":1736633194532,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633195384,"Executor ID":"5","Executor Info":{"Host":"172.35.93.136","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633195384}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"5","Host":"172.35.93.136","Port":45885},"Maximum Memory":6253707264,"Timestamp":1736633195587,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633197411,"Executor ID":"2","Executor Info":{"Host":"172.38.127.204","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633197410}}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1736633197505,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"rdd at DynamicFrame.scala:2028","Number of Tasks":3,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan parquet \"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"FileScanRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan parquet \"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.rdd(Dataset.scala:3893)\ncom.amazonaws.services.glue.DynamicFrame$.apply(DynamicFrame.scala:2028)\ncom.amazonaws.services.glue.SparkSQLDataSource.getDynamicFrame(DataSource.scala:771)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame(DataSource.scala:95)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame$(DataSource.scala:95)\ncom.amazonaws.services.glue.AbstractSparkSQLDataSource.getDynamicFrame(DataSource.scala:693)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"fromRDD at DynamicFrame.scala:297","Number of Tasks":6,"RDD Info":[{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"59\",\"name\":\"treeAggregate\"}","Callsite":"fromRDD at DynamicFrame.scala:297","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":6,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":63,"Name":"ShuffledRDD","Scope":"{\"id\":\"59\",\"name\":\"treeAggregate\"}","Callsite":"fromRDD at DynamicFrame.scala:297","Parent IDs":[62],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":6,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[4],"Details":"org.apache.spark.sql.glue.util.SchemaUtils$.fromRDD(SchemaUtils.scala:78)\ncom.amazonaws.services.glue.DynamicFrame.recomputeSchema(DynamicFrame.scala:297)\ncom.amazonaws.services.glue.DynamicFrame.schema(DynamicFrame.scala:274)\ncom.amazonaws.services.glue.DynamicFrame.toDF(DynamicFrame.scala:363)\ncom.amazonaws.services.glue.dq.EvaluateDataQuality$.processRows(EvaluateDataQuality.scala:64)\ncom.amazonaws.services.glue.dq.EvaluateDataQuality.processRows(EvaluateDataQuality.scala)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"map at DynamicFrame.scala:939","Number of Tasks":20,"RDD Info":[{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"51\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:939","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"18\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:2028","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"filter\"}","Callsite":"filter at DynamicFrame.scala:165","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"mapPartitions\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"ShuffledRowRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"mapPartitionsWithIndex\"}","Callsite":"mapPartitionsWithIndex at DynamicFrame.scala:142","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"SQLExecutionRDD","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[1],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:418)\ncom.amazonaws.services.glue.DynamicFrame.join(DynamicFrame.scala:939)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"map at DynamicFrame.scala:946","Number of Tasks":11,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:946","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"20\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"29\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"47\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"UnionRDD","Callsite":"UnionRDD at DataSource.scala:477","Parent IDs":[20,23,26,29,32,35,38,41,44,47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"NewHadoopRDD","Scope":"{\"id\":\"31\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"42\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"NewHadoopRDD","Scope":"{\"id\":\"25\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"30\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"35\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"52\",\"name\":\"mapPartitionsWithIndex\"}","Callsite":"mapPartitionsWithIndex at DynamicFrame.scala:142","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"NewHadoopRDD","Scope":"{\"id\":\"37\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"NewHadoopRDD","Scope":"{\"id\":\"46\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"53\",\"name\":\"filter\"}","Callsite":"filter at DynamicFrame.scala:165","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"NewHadoopRDD","Scope":"{\"id\":\"34\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"38\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"NewHadoopRDD","Scope":"{\"id\":\"22\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"48\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"NewHadoopRDD","Scope":"{\"id\":\"40\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"NewHadoopRDD","Scope":"{\"id\":\"43\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"23\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"NewHadoopRDD","Scope":"{\"id\":\"28\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"NewHadoopRDD","Scope":"{\"id\":\"19\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"27\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"32\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:418)\ncom.amazonaws.services.glue.DynamicFrame.join(DynamicFrame.scala:946)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"fromRDD at DynamicFrame.scala:297","Number of Tasks":36,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"59\",\"name\":\"treeAggregate\"}","Callsite":"fromRDD at DynamicFrame.scala:297","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":36,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"56\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:956","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":36,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":60,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"58\",\"name\":\"filter\"}","Callsite":"filter at DynamicFrame.scala:165","Parent IDs":[59],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":36,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":55,"Name":"CoGroupedRDD","Scope":"{\"id\":\"55\",\"name\":\"join\"}","Callsite":"join at DynamicFrame.scala:953","Parent IDs":[54,51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":36,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"57\",\"name\":\"mapPartitionsWithIndex\"}","Callsite":"mapPartitionsWithIndex at DynamicFrame.scala:142","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":36,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":57,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"55\",\"name\":\"join\"}","Callsite":"join at DynamicFrame.scala:953","Parent IDs":[56],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":36,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"55\",\"name\":\"join\"}","Callsite":"join at DynamicFrame.scala:953","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":36,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"59\",\"name\":\"treeAggregate\"}","Callsite":"fromRDD at DynamicFrame.scala:297","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":36,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[2,3],"Details":"org.apache.spark.sql.glue.util.SchemaUtils$.fromRDD(SchemaUtils.scala:78)\ncom.amazonaws.services.glue.DynamicFrame.recomputeSchema(DynamicFrame.scala:297)\ncom.amazonaws.services.glue.DynamicFrame.schema(DynamicFrame.scala:274)\ncom.amazonaws.services.glue.DynamicFrame.toDF(DynamicFrame.scala:363)\ncom.amazonaws.services.glue.dq.EvaluateDataQuality$.processRows(EvaluateDataQuality.scala:64)\ncom.amazonaws.services.glue.dq.EvaluateDataQuality.processRows(EvaluateDataQuality.scala)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}],"Stage IDs":[1,5,2,3,4],"Properties":{"spark.rdd.scope":"{\"id\":\"59\",\"name\":\"treeAggregate\"}","__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"rdd at DynamicFrame.scala:2028","Number of Tasks":3,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan parquet \"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"FileScanRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan parquet \"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.rdd(Dataset.scala:3893)\ncom.amazonaws.services.glue.DynamicFrame$.apply(DynamicFrame.scala:2028)\ncom.amazonaws.services.glue.SparkSQLDataSource.getDynamicFrame(DataSource.scala:771)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame(DataSource.scala:95)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame$(DataSource.scala:95)\ncom.amazonaws.services.glue.AbstractSparkSQLDataSource.getDynamicFrame(DataSource.scala:693)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Submission Time":1736633197540,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.rdd.scope":"{\"id\":\"59\",\"name\":\"treeAggregate\"}","resource.executor.cores":"4","__fetch_continuous_blocks_in_batch_enabled":"true","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"2","Host":"172.38.127.204","Port":35305},"Maximum Memory":6253707264,"Timestamp":1736633197544,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"map at DynamicFrame.scala:946","Number of Tasks":11,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:946","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"20\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"29\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"47\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"UnionRDD","Callsite":"UnionRDD at DataSource.scala:477","Parent IDs":[20,23,26,29,32,35,38,41,44,47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"NewHadoopRDD","Scope":"{\"id\":\"31\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"42\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"NewHadoopRDD","Scope":"{\"id\":\"25\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"30\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"35\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"52\",\"name\":\"mapPartitionsWithIndex\"}","Callsite":"mapPartitionsWithIndex at DynamicFrame.scala:142","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"NewHadoopRDD","Scope":"{\"id\":\"37\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"NewHadoopRDD","Scope":"{\"id\":\"46\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"53\",\"name\":\"filter\"}","Callsite":"filter at DynamicFrame.scala:165","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"NewHadoopRDD","Scope":"{\"id\":\"34\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"38\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"NewHadoopRDD","Scope":"{\"id\":\"22\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"48\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"NewHadoopRDD","Scope":"{\"id\":\"40\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"NewHadoopRDD","Scope":"{\"id\":\"43\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"23\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"NewHadoopRDD","Scope":"{\"id\":\"28\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"NewHadoopRDD","Scope":"{\"id\":\"19\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"27\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"32\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:418)\ncom.amazonaws.services.glue.DynamicFrame.join(DynamicFrame.scala:946)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Submission Time":1736633197602,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.rdd.scope":"{\"id\":\"59\",\"name\":\"treeAggregate\"}","resource.executor.cores":"4","__fetch_continuous_blocks_in_batch_enabled":"true","emr.outputNamespace":"user","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1736633197584,"Executor ID":"1","Host":"172.36.182.108","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":1,"Attempt":0,"Partition ID":1,"Launch Time":1736633197590,"Executor ID":"7","Host":"172.34.194.64","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":2,"Attempt":0,"Partition ID":2,"Launch Time":1736633197591,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1736633197623,"Executor ID":"7","Host":"172.34.194.64","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":1,"Attempt":0,"Partition ID":1,"Launch Time":1736633197633,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":2,"Attempt":0,"Partition ID":2,"Launch Time":1736633197634,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":3,"Attempt":0,"Partition ID":3,"Launch Time":1736633197635,"Executor ID":"1","Host":"172.36.182.108","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":4,"Attempt":0,"Partition ID":4,"Launch Time":1736633197635,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":5,"Attempt":0,"Partition ID":5,"Launch Time":1736633197636,"Executor ID":"7","Host":"172.34.194.64","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":6,"Attempt":0,"Partition ID":6,"Launch Time":1736633197637,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":7,"Attempt":0,"Partition ID":7,"Launch Time":1736633197640,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":8,"Attempt":0,"Partition ID":8,"Launch Time":1736633197640,"Executor ID":"1","Host":"172.36.182.108","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":9,"Attempt":0,"Partition ID":9,"Launch Time":1736633197641,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":10,"Attempt":0,"Partition ID":10,"Launch Time":1736633197642,"Executor ID":"7","Host":"172.34.194.64","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633198062,"Executor ID":"4","Executor Info":{"Host":"172.36.252.141","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633198062}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"4","Host":"172.36.252.141","Port":44125},"Maximum Memory":6253707264,"Timestamp":1736633198244,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerExecutorAdded","Timestamp":1736633198782,"Executor ID":"6","Executor Info":{"Host":"172.36.156.9","Total Cores":4,"Log Urls":{},"Attributes":{},"Resources":{},"Resource Profile Id":0,"Registration Time":1736633198782}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"6","Host":"172.36.156.9","Port":44867},"Maximum Memory":6253707264,"Timestamp":1736633198991,"Maximum Onheap Memory":6253707264,"Maximum Offheap Memory":0}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: KRvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: KRvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"3573","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"40","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"21024841","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"660064","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"649","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":11,"Index":7,"Attempt":0,"Partition ID":7,"Launch Time":1736633197640,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633201389,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":3573,"Value":3573,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":40,"Value":40,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":21024841,"Value":21024841,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":660064,"Value":660064,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":649,"Value":649,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":3573,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":40,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":21024841,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":660064,"Records Read":649},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":7,"Attempt":1,"Partition ID":7,"Launch Time":1736633201393,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: RUvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: RUvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"3772","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"59","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"4720404","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"829180","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"400","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":10,"Index":6,"Attempt":0,"Partition ID":6,"Launch Time":1736633197637,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633201504,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":3772,"Value":7345,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":59,"Value":99,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":4720404,"Value":25745245,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":829180,"Value":1489244,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":400,"Value":1049,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":3772,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":59,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":4720404,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":829180,"Records Read":400},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":6,"Attempt":1,"Partition ID":6,"Launch Time":1736633201506,"Executor ID":"2","Host":"172.38.127.204","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":2,"Attempt":0,"Partition ID":2,"Launch Time":1736633197591,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633201821,"Failed":false,"Killed":false,"Accumulables":[{"ID":46,"Name":"number of output rows","Update":"2443","Value":"2443","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":47,"Name":"number of input batches","Update":"1","Value":"1","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":48,"Name":"duration","Update":"2011","Value":"2011","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":49,"Name":"number of output rows","Update":"2443","Value":"2443","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":51,"Name":"scan time","Update":"1860","Value":"1860","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":56,"Name":"data size","Update":"1780960","Value":"1780960","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":75,"Name":"shuffle bytes written","Update":"970353","Value":"970353","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":76,"Name":"shuffle records written","Update":"2443","Value":"2443","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":77,"Name":"shuffle write time","Update":"13620641","Value":"13620641","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":89,"Name":"internal.metrics.executorDeserializeTime","Update":1152,"Value":1152,"Internal":true,"Count Failed Values":true},{"ID":90,"Name":"internal.metrics.executorDeserializeCpuTime","Update":370561283,"Value":370561283,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.executorRunTime","Update":3034,"Value":3034,"Internal":true,"Count Failed Values":true},{"ID":92,"Name":"internal.metrics.executorCpuTime","Update":910001572,"Value":910001572,"Internal":true,"Count Failed Values":true},{"ID":93,"Name":"internal.metrics.resultSize","Update":2993,"Value":2993,"Internal":true,"Count Failed Values":true},{"ID":94,"Name":"internal.metrics.jvmGCTime","Update":73,"Value":73,"Internal":true,"Count Failed Values":true},{"ID":95,"Name":"internal.metrics.resultSerializationTime","Update":3,"Value":3,"Internal":true,"Count Failed Values":true},{"ID":117,"Name":"internal.metrics.shuffle.write.bytesWritten","Update":970353,"Value":970353,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":2443,"Value":2443,"Internal":true,"Count Failed Values":true},{"ID":119,"Name":"internal.metrics.shuffle.write.writeTime","Update":13620641,"Value":13620641,"Internal":true,"Count Failed Values":true},{"ID":120,"Name":"internal.metrics.input.bytesRead","Update":163959,"Value":163959,"Internal":true,"Count Failed Values":true},{"ID":121,"Name":"internal.metrics.input.recordsRead","Update":2443,"Value":2443,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":1152,"Executor Deserialize CPU Time":370561283,"Executor Run Time":3034,"Executor CPU Time":910001572,"Peak Execution Memory":0,"Result Size":2993,"JVM GC Time":73,"Result Serialization Time":3,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":970353,"Shuffle Write Time":13620641,"Shuffle Records Written":2443},"Input Metrics":{"Bytes Read":163959,"Records Read":2443},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: JPvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: JPvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"4616","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"75","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"9177417","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"3677522","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"2827","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":13,"Index":9,"Attempt":0,"Partition ID":9,"Launch Time":1736633197641,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633202334,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":4616,"Value":11961,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":75,"Value":174,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":9177417,"Value":34922662,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":3677522,"Value":5166766,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":2827,"Value":3876,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":258494608,"JVMOffHeapMemory":144382520,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":976543,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":976543,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16849176,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":22,"MinorGCTime":241,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":241},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":4616,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":75,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":9177417,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3677522,"Records Read":2827},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":9,"Attempt":1,"Partition ID":9,"Launch Time":1736633202336,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1736633197584,"Executor ID":"1","Host":"172.36.182.108","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633202367,"Failed":false,"Killed":false,"Accumulables":[{"ID":46,"Name":"number of output rows","Update":"2753","Value":"5196","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":47,"Name":"number of input batches","Update":"1","Value":"2","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":48,"Name":"duration","Update":"2320","Value":"4331","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":49,"Name":"number of output rows","Update":"2753","Value":"5196","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":51,"Name":"scan time","Update":"2163","Value":"4023","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":56,"Name":"data size","Update":"2008280","Value":"3789240","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":75,"Name":"shuffle bytes written","Update":"1179816","Value":"2150169","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":76,"Name":"shuffle records written","Update":"2753","Value":"5196","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":77,"Name":"shuffle write time","Update":"18411248","Value":"32031889","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":89,"Name":"internal.metrics.executorDeserializeTime","Update":1193,"Value":2345,"Internal":true,"Count Failed Values":true},{"ID":90,"Name":"internal.metrics.executorDeserializeCpuTime","Update":427542193,"Value":798103476,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.executorRunTime","Update":3511,"Value":6545,"Internal":true,"Count Failed Values":true},{"ID":92,"Name":"internal.metrics.executorCpuTime","Update":1003073384,"Value":1913074956,"Internal":true,"Count Failed Values":true},{"ID":93,"Name":"internal.metrics.resultSize","Update":2993,"Value":5986,"Internal":true,"Count Failed Values":true},{"ID":94,"Name":"internal.metrics.jvmGCTime","Update":87,"Value":160,"Internal":true,"Count Failed Values":true},{"ID":95,"Name":"internal.metrics.resultSerializationTime","Update":4,"Value":7,"Internal":true,"Count Failed Values":true},{"ID":117,"Name":"internal.metrics.shuffle.write.bytesWritten","Update":1179816,"Value":2150169,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":2753,"Value":5196,"Internal":true,"Count Failed Values":true},{"ID":119,"Name":"internal.metrics.shuffle.write.writeTime","Update":18411248,"Value":32031889,"Internal":true,"Count Failed Values":true},{"ID":120,"Name":"internal.metrics.input.bytesRead","Update":643163,"Value":807122,"Internal":true,"Count Failed Values":true},{"ID":121,"Name":"internal.metrics.input.recordsRead","Update":2753,"Value":5196,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":1193,"Executor Deserialize CPU Time":427542193,"Executor Run Time":3511,"Executor CPU Time":1003073384,"Peak Execution Memory":0,"Result Size":2993,"JVM GC Time":87,"Result Serialization Time":4,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":1179816,"Shuffle Write Time":18411248,"Shuffle Records Written":2753},"Input Metrics":{"Bytes Read":643163,"Records Read":2753},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: MXvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"4666","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"88","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"11037868","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"416352","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"334","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":14,"Index":10,"Attempt":0,"Partition ID":10,"Launch Time":1736633197642,"Executor ID":"7","Host":"172.34.194.64","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633202438,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":4666,"Value":16627,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":88,"Value":262,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":11037868,"Value":45960530,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":416352,"Value":5583118,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":334,"Value":4210,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":4666,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":88,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":11037868,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":416352,"Records Read":334},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":10,"Attempt":1,"Partition ID":10,"Launch Time":1736633202439,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: KRvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: KRvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"1436","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"18","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"14900715","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"661794","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"649","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":15,"Index":7,"Attempt":1,"Partition ID":7,"Launch Time":1736633201393,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633202842,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":1436,"Value":18063,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":18,"Value":280,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":14900715,"Value":60861245,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":661794,"Value":6244912,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":649,"Value":4859,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":1436,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":18,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":14900715,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":661794,"Records Read":649},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":7,"Attempt":2,"Partition ID":7,"Launch Time":1736633202845,"Executor ID":"6","Host":"172.36.156.9","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: MXvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"531","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"14","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"3578854","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"404818","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"334","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":18,"Index":10,"Attempt":1,"Partition ID":10,"Launch Time":1736633202439,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633202985,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":531,"Value":18594,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":14,"Value":294,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":3578854,"Value":64440099,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":404818,"Value":6649730,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":334,"Value":5193,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":531,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":14,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":3578854,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":404818,"Records Read":334},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":10,"Attempt":2,"Partition ID":10,"Launch Time":1736633202986,"Executor ID":"1","Host":"172.36.182.108","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":1,"Attempt":0,"Partition ID":1,"Launch Time":1736633197590,"Executor ID":"7","Host":"172.34.194.64","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633203062,"Failed":false,"Killed":false,"Accumulables":[{"ID":46,"Name":"number of output rows","Update":"1906","Value":"7102","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":47,"Name":"number of input batches","Update":"1","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":48,"Name":"duration","Update":"2394","Value":"6725","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":49,"Name":"number of output rows","Update":"1906","Value":"7102","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":51,"Name":"scan time","Update":"2265","Value":"6288","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":56,"Name":"data size","Update":"1482080","Value":"5271320","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":75,"Name":"shuffle bytes written","Update":"835328","Value":"2985497","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":76,"Name":"shuffle records written","Update":"1906","Value":"7102","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":77,"Name":"shuffle write time","Update":"73644535","Value":"105676424","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":89,"Name":"internal.metrics.executorDeserializeTime","Update":1746,"Value":4091,"Internal":true,"Count Failed Values":true},{"ID":90,"Name":"internal.metrics.executorDeserializeCpuTime","Update":442249629,"Value":1240353105,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.executorRunTime","Update":3664,"Value":10209,"Internal":true,"Count Failed Values":true},{"ID":92,"Name":"internal.metrics.executorCpuTime","Update":935884481,"Value":2848959437,"Internal":true,"Count Failed Values":true},{"ID":93,"Name":"internal.metrics.resultSize","Update":2992,"Value":8978,"Internal":true,"Count Failed Values":true},{"ID":94,"Name":"internal.metrics.jvmGCTime","Update":93,"Value":253,"Internal":true,"Count Failed Values":true},{"ID":95,"Name":"internal.metrics.resultSerializationTime","Update":4,"Value":11,"Internal":true,"Count Failed Values":true},{"ID":117,"Name":"internal.metrics.shuffle.write.bytesWritten","Update":835328,"Value":2985497,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":1906,"Value":7102,"Internal":true,"Count Failed Values":true},{"ID":119,"Name":"internal.metrics.shuffle.write.writeTime","Update":73644535,"Value":105676424,"Internal":true,"Count Failed Values":true},{"ID":120,"Name":"internal.metrics.input.bytesRead","Update":200103,"Value":1007225,"Internal":true,"Count Failed Values":true},{"ID":121,"Name":"internal.metrics.input.recordsRead","Update":1906,"Value":7102,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":1746,"Executor Deserialize CPU Time":442249629,"Executor Run Time":3664,"Executor CPU Time":935884481,"Peak Execution Memory":0,"Result Size":2992,"JVM GC Time":93,"Result Serialization Time":4,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":835328,"Shuffle Write Time":73644535,"Shuffle Records Written":1906},"Input Metrics":{"Bytes Read":200103,"Records Read":1906},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"rdd at DynamicFrame.scala:2028","Number of Tasks":3,"RDD Info":[{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan parquet \"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":8,"Name":"FileScanRDD","Scope":"{\"id\":\"16\",\"name\":\"Scan parquet \"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"13\",\"name\":\"WholeStageCodegen (1)\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":3,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.sql.Dataset.rdd(Dataset.scala:3893)\ncom.amazonaws.services.glue.DynamicFrame$.apply(DynamicFrame.scala:2028)\ncom.amazonaws.services.glue.SparkSQLDataSource.getDynamicFrame(DataSource.scala:771)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame(DataSource.scala:95)\ncom.amazonaws.services.glue.DataSource.getDynamicFrame$(DataSource.scala:95)\ncom.amazonaws.services.glue.AbstractSparkSQLDataSource.getDynamicFrame(DataSource.scala:693)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Submission Time":1736633197540,"Completion Time":1736633203064,"Accumulables":[{"ID":46,"Name":"number of output rows","Value":"7102","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":47,"Name":"number of input batches","Value":"3","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":48,"Name":"duration","Value":"6725","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":49,"Name":"number of output rows","Value":"7102","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":51,"Name":"scan time","Value":"6288","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":56,"Name":"data size","Value":"5271320","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":75,"Name":"shuffle bytes written","Value":"2985497","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":76,"Name":"shuffle records written","Value":"7102","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":77,"Name":"shuffle write time","Value":"105676424","Internal":true,"Count Failed Values":true,"Metadata":"sql"},{"ID":89,"Name":"internal.metrics.executorDeserializeTime","Value":4091,"Internal":true,"Count Failed Values":true},{"ID":90,"Name":"internal.metrics.executorDeserializeCpuTime","Value":1240353105,"Internal":true,"Count Failed Values":true},{"ID":91,"Name":"internal.metrics.executorRunTime","Value":10209,"Internal":true,"Count Failed Values":true},{"ID":92,"Name":"internal.metrics.executorCpuTime","Value":2848959437,"Internal":true,"Count Failed Values":true},{"ID":93,"Name":"internal.metrics.resultSize","Value":8978,"Internal":true,"Count Failed Values":true},{"ID":94,"Name":"internal.metrics.jvmGCTime","Value":253,"Internal":true,"Count Failed Values":true},{"ID":95,"Name":"internal.metrics.resultSerializationTime","Value":11,"Internal":true,"Count Failed Values":true},{"ID":117,"Name":"internal.metrics.shuffle.write.bytesWritten","Value":2985497,"Internal":true,"Count Failed Values":true},{"ID":118,"Name":"internal.metrics.shuffle.write.recordsWritten","Value":7102,"Internal":true,"Count Failed Values":true},{"ID":119,"Name":"internal.metrics.shuffle.write.writeTime","Value":105676424,"Internal":true,"Count Failed Values":true},{"ID":120,"Name":"internal.metrics.input.bytesRead","Value":1007225,"Internal":true,"Count Failed Values":true},{"ID":121,"Name":"internal.metrics.input.recordsRead","Value":7102,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"map at DynamicFrame.scala:939","Number of Tasks":20,"RDD Info":[{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"51\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:939","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"18\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:2028","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"filter\"}","Callsite":"filter at DynamicFrame.scala:165","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"mapPartitions\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"ShuffledRowRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"mapPartitionsWithIndex\"}","Callsite":"mapPartitionsWithIndex at DynamicFrame.scala:142","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"SQLExecutionRDD","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[1],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:418)\ncom.amazonaws.services.glue.DynamicFrame.join(DynamicFrame.scala:939)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Submission Time":1736633203078,"Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0},"Properties":{"spark.rdd.scope":"{\"id\":\"59\",\"name\":\"treeAggregate\"}","resource.executor.cores":"4","__fetch_continuous_blocks_in_batch_enabled":"true","emr.outputNamespace":"user","spark.rdd.scope.noOverride":"true"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1736633203095,"Executor ID":"1","Host":"172.36.182.108","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":22,"Index":1,"Attempt":0,"Partition ID":1,"Launch Time":1736633203097,"Executor ID":"9","Host":"172.38.148.117","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":23,"Index":2,"Attempt":0,"Partition ID":2,"Launch Time":1736633203098,"Executor ID":"7","Host":"172.34.194.64","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":24,"Index":3,"Attempt":0,"Partition ID":3,"Launch Time":1736633203098,"Executor ID":"9","Host":"172.38.148.117","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":25,"Index":4,"Attempt":0,"Partition ID":4,"Launch Time":1736633203098,"Executor ID":"7","Host":"172.34.194.64","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":26,"Index":5,"Attempt":0,"Partition ID":5,"Launch Time":1736633203099,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":27,"Index":6,"Attempt":0,"Partition ID":6,"Launch Time":1736633203100,"Executor ID":"4","Host":"172.36.252.141","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":28,"Index":7,"Attempt":0,"Partition ID":7,"Launch Time":1736633203102,"Executor ID":"5","Host":"172.35.93.136","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":29,"Index":8,"Attempt":0,"Partition ID":8,"Launch Time":1736633203102,"Executor ID":"6","Host":"172.36.156.9","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":30,"Index":9,"Attempt":0,"Partition ID":9,"Launch Time":1736633203103,"Executor ID":"2","Host":"172.38.127.204","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":31,"Index":10,"Attempt":0,"Partition ID":10,"Launch Time":1736633203103,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":32,"Index":11,"Attempt":0,"Partition ID":11,"Launch Time":1736633203103,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":33,"Index":12,"Attempt":0,"Partition ID":12,"Launch Time":1736633203104,"Executor ID":"4","Host":"172.36.252.141","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":34,"Index":13,"Attempt":0,"Partition ID":13,"Launch Time":1736633203104,"Executor ID":"5","Host":"172.35.93.136","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":35,"Index":14,"Attempt":0,"Partition ID":14,"Launch Time":1736633203105,"Executor ID":"6","Host":"172.36.156.9","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":36,"Index":15,"Attempt":0,"Partition ID":15,"Launch Time":1736633203105,"Executor ID":"2","Host":"172.38.127.204","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":37,"Index":16,"Attempt":0,"Partition ID":16,"Launch Time":1736633203105,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":38,"Index":17,"Attempt":0,"Partition ID":17,"Launch Time":1736633203106,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":39,"Index":18,"Attempt":0,"Partition ID":18,"Launch Time":1736633203109,"Executor ID":"4","Host":"172.36.252.141","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":40,"Index":19,"Attempt":0,"Partition ID":19,"Launch Time":1736633203111,"Executor ID":"5","Host":"172.35.93.136","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: JPvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: JPvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"1049","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"13","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"11053214","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"3671648","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"2827","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":17,"Index":9,"Attempt":1,"Partition ID":9,"Launch Time":1736633202336,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633203403,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":1049,"Value":19643,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":13,"Value":307,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":11053214,"Value":75493313,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":3671648,"Value":10321378,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":2827,"Value":8020,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":1049,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":13,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":11053214,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3671648,"Records Read":2827},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":41,"Index":9,"Attempt":2,"Partition ID":9,"Launch Time":1736633203406,"Executor ID":"6","Host":"172.36.156.9","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: RUvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: RUvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"5723","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"100","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"19289112","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"3390585","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"1767","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":9,"Index":5,"Attempt":0,"Partition ID":5,"Launch Time":1736633197636,"Executor ID":"7","Host":"172.34.194.64","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633203465,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":5723,"Value":25366,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":100,"Value":407,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":19289112,"Value":94782425,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":3390585,"Value":13711963,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":1767,"Value":9787,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":5723,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":100,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":19289112,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3390585,"Records Read":1767},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":42,"Index":5,"Attempt":1,"Partition ID":5,"Launch Time":1736633203467,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: MXvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"971","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"16","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"4608490","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"404818","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"334","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":20,"Index":10,"Attempt":2,"Partition ID":10,"Launch Time":1736633202986,"Executor ID":"1","Host":"172.36.182.108","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204014,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":971,"Value":26337,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":16,"Value":423,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":4608490,"Value":99390915,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":404818,"Value":14116781,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":334,"Value":10121,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":971,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":16,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":4608490,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":404818,"Records Read":334},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":43,"Index":10,"Attempt":3,"Partition ID":10,"Launch Time":1736633204015,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: RUvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: RUvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"954","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"21","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"6136742","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"3375711","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"1767","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":42,"Index":5,"Attempt":1,"Partition ID":5,"Launch Time":1736633203467,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204454,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":954,"Value":27291,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":21,"Value":444,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":6136742,"Value":105527657,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":3375711,"Value":17492492,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":1767,"Value":11888,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":954,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":21,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":6136742,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":3375711,"Records Read":1767},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":44,"Index":5,"Attempt":2,"Partition ID":5,"Launch Time":1736633204455,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Killed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"ExceptionFailure","Class Name":"com.amazonaws.services.glue.util.FatalException","Description":"Unable to parse file: MXvideos.csv\n","Stack Trace":[{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNextFailSafe","File Name":"JacksonReader.scala","Line Number":94},{"Declaring Class":"com.amazonaws.services.glue.readers.JacksonReader","Method Name":"hasNext","File Name":"JacksonReader.scala","Line Number":38},{"Declaring Class":"com.amazonaws.services.glue.readers.CSVReader","Method Name":"hasNext","File Name":"CSVReader.scala","Line Number":185},{"Declaring Class":"com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable","Method Name":"nextKeyValue","File Name":"TapeHadoopRecordReaderSplittable.scala","Line Number":95},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"$anonfun$hasNext$1","File Name":"NewHadoopRDD.scala","Line Number":264},{"Declaring Class":"scala.runtime.java8.JFunction0$mcZ$sp","Method Name":"apply","File Name":"JFunction0$mcZ$sp.java","Line Number":23},{"Declaring Class":"org.apache.spark.util.FileAccessContext$","Method Name":"withContext","File Name":"FileAccessContext.scala","Line Number":41},{"Declaring Class":"org.apache.spark.rdd.NewHadoopRDD$$anon$1","Method Name":"hasNext","File Name":"NewHadoopRDD.scala","Line Number":261},{"Declaring Class":"org.apache.spark.InterruptibleIterator","Method Name":"hasNext","File Name":"InterruptibleIterator.scala","Line Number":37},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"scala.collection.Iterator$$anon$12","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":513},{"Declaring Class":"scala.collection.Iterator$$anon$10","Method Name":"hasNext","File Name":"Iterator.scala","Line Number":460},{"Declaring Class":"org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter","Method Name":"write","File Name":"BypassMergeSortShuffleWriter.java","Line Number":183},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"doWrite","File Name":"ShuffleWriteProcessor.scala","Line Number":45},{"Declaring Class":"org.apache.spark.shuffle.ShuffleWriteProcessor","Method Name":"write","File Name":"ShuffleWriteProcessor.scala","Line Number":69},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":104},{"Declaring Class":"org.apache.spark.scheduler.ShuffleMapTask","Method Name":"runTask","File Name":"ShuffleMapTask.scala","Line Number":54},{"Declaring Class":"org.apache.spark.TaskContext","Method Name":"runTaskWithListeners","File Name":"TaskContext.scala","Line Number":174},{"Declaring Class":"org.apache.spark.scheduler.Task","Method Name":"run","File Name":"Task.scala","Line Number":152},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"$anonfun$run$4","File Name":"Executor.scala","Line Number":632},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally","File Name":"SparkErrorUtils.scala","Line Number":64},{"Declaring Class":"org.apache.spark.util.SparkErrorUtils","Method Name":"tryWithSafeFinally$","File Name":"SparkErrorUtils.scala","Line Number":61},{"Declaring Class":"org.apache.spark.util.Utils$","Method Name":"tryWithSafeFinally","File Name":"Utils.scala","Line Number":96},{"Declaring Class":"org.apache.spark.executor.Executor$TaskRunner","Method Name":"run","File Name":"Executor.scala","Line Number":635},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor","Method Name":"runWorker","File Name":"ThreadPoolExecutor.java","Line Number":1136},{"Declaring Class":"java.util.concurrent.ThreadPoolExecutor$Worker","Method Name":"run","File Name":"ThreadPoolExecutor.java","Line Number":635},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}],"Full Stack Trace":"com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n","Accumulator Updates":[{"ID":126,"Update":"669","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"12","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"2594997","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"401698","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"334","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":43,"Index":10,"Attempt":3,"Partition ID":10,"Launch Time":1736633204015,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204694,"Failed":true,"Killed":false,"Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Update":669,"Value":27960,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Update":12,"Value":456,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Update":0,"Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Update":2594997,"Value":108122654,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Update":401698,"Value":17894190,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Update":334,"Value":12222,"Internal":true,"Count Failed Values":true}]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":669,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":12,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":2594997,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":401698,"Records Read":334},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"map at DynamicFrame.scala:939","Number of Tasks":20,"RDD Info":[{"RDD ID":51,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"51\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:939","Parent IDs":[50],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"18\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:2028","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"11\",\"name\":\"DeserializeToObject\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"50\",\"name\":\"filter\"}","Callsite":"filter at DynamicFrame.scala:165","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"17\",\"name\":\"mapPartitions\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":13,"Name":"ShuffledRowRDD","Scope":"{\"id\":\"12\",\"name\":\"Exchange\"}","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"49\",\"name\":\"mapPartitionsWithIndex\"}","Callsite":"mapPartitionsWithIndex at DynamicFrame.scala:142","Parent IDs":[17],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":15,"Name":"SQLExecutionRDD","Callsite":"rdd at DynamicFrame.scala:2028","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"UNORDERED","Number of Partitions":20,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[1],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:418)\ncom.amazonaws.services.glue.DynamicFrame.join(DynamicFrame.scala:939)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Submission Time":1736633203078,"Completion Time":1736633204703,"Failure Reason":"Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulables":[],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"map at DynamicFrame.scala:946","Number of Tasks":11,"RDD Info":[{"RDD ID":54,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"54\",\"name\":\"map\"}","Callsite":"map at DynamicFrame.scala:946","Parent IDs":[53],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"20\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"29\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"47\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":48,"Name":"UnionRDD","Callsite":"UnionRDD at DataSource.scala:477","Parent IDs":[20,23,26,29,32,35,38,41,44,47],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"39\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":30,"Name":"NewHadoopRDD","Scope":"{\"id\":\"31\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"36\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"41\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"45\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"42\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":24,"Name":"NewHadoopRDD","Scope":"{\"id\":\"25\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"30\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"35\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"21\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"52\",\"name\":\"mapPartitionsWithIndex\"}","Callsite":"mapPartitionsWithIndex at DynamicFrame.scala:142","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":36,"Name":"NewHadoopRDD","Scope":"{\"id\":\"37\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":45,"Name":"NewHadoopRDD","Scope":"{\"id\":\"46\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"53\",\"name\":\"filter\"}","Callsite":"filter at DynamicFrame.scala:165","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":11,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"44\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":33,"Name":"NewHadoopRDD","Scope":"{\"id\":\"34\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":2,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"26\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"38\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":21,"Name":"NewHadoopRDD","Scope":"{\"id\":\"22\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"48\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":39,"Name":"NewHadoopRDD","Scope":"{\"id\":\"40\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"24\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":42,"Name":"NewHadoopRDD","Scope":"{\"id\":\"43\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"33\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"23\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":27,"Name":"NewHadoopRDD","Scope":"{\"id\":\"28\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":18,"Name":"NewHadoopRDD","Scope":"{\"id\":\"19\",\"name\":\"newAPIHadoopRDD\"}","Callsite":"newAPIHadoopRDD at DataSource.scala:434","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"27\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:441","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"32\",\"name\":\"map\"}","Callsite":"map at DataSource.scala:434","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use Off Heap":false,"Deserialized":false,"Replication":1},"Barrier":false,"DeterministicLevel":"DETERMINATE","Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.map(RDD.scala:418)\ncom.amazonaws.services.glue.DynamicFrame.join(DynamicFrame.scala:946)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\njava.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\njava.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.base/java.lang.reflect.Method.invoke(Method.java:569)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\npy4j.Gateway.invoke(Gateway.java:282)\npy4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\npy4j.commands.CallCommand.execute(CallCommand.java:79)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:840)","Submission Time":1736633197602,"Completion Time":1736633204707,"Failure Reason":"Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulables":[{"ID":126,"Name":"internal.metrics.executorRunTime","Value":27960,"Internal":true,"Count Failed Values":true},{"ID":129,"Name":"internal.metrics.jvmGCTime","Value":456,"Internal":true,"Count Failed Values":true},{"ID":153,"Name":"internal.metrics.shuffle.write.recordsWritten","Value":0,"Internal":true,"Count Failed Values":true},{"ID":154,"Name":"internal.metrics.shuffle.write.writeTime","Value":108122654,"Internal":true,"Count Failed Values":true},{"ID":155,"Name":"internal.metrics.input.bytesRead","Value":17894190,"Internal":true,"Count Failed Values":true},{"ID":156,"Name":"internal.metrics.input.recordsRead","Value":12222,"Internal":true,"Count Failed Values":true}],"Resource Profile Id":0,"Shuffle Push Enabled":false,"Shuffle Push Mergers Count":0}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1736633204713,"Job Result":{"Result":"JobFailed","Exception":{"Message":"Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Stack Trace":[{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"failJobAndIndependentStages","File Name":"DAGScheduler.scala","Line Number":3083},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"$anonfun$abortStage$2","File Name":"DAGScheduler.scala","Line Number":3019},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"$anonfun$abortStage$2$adapted","File Name":"DAGScheduler.scala","Line Number":3018},{"Declaring Class":"scala.collection.mutable.ResizableArray","Method Name":"foreach","File Name":"ResizableArray.scala","Line Number":62},{"Declaring Class":"scala.collection.mutable.ResizableArray","Method Name":"foreach$","File Name":"ResizableArray.scala","Line Number":55},{"Declaring Class":"scala.collection.mutable.ArrayBuffer","Method Name":"foreach","File Name":"ArrayBuffer.scala","Line Number":49},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"abortStage","File Name":"DAGScheduler.scala","Line Number":3018},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"$anonfun$handleTaskSetFailed$1","File Name":"DAGScheduler.scala","Line Number":1324},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"$anonfun$handleTaskSetFailed$1$adapted","File Name":"DAGScheduler.scala","Line Number":1324},{"Declaring Class":"scala.Option","Method Name":"foreach","File Name":"Option.scala","Line Number":407},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"handleTaskSetFailed","File Name":"DAGScheduler.scala","Line Number":1324},{"Declaring Class":"org.apache.spark.scheduler.DAGSchedulerEventProcessLoop","Method Name":"doOnReceive","File Name":"DAGScheduler.scala","Line Number":3301},{"Declaring Class":"org.apache.spark.scheduler.DAGSchedulerEventProcessLoop","Method Name":"onReceive","File Name":"DAGScheduler.scala","Line Number":3235},{"Declaring Class":"org.apache.spark.scheduler.DAGSchedulerEventProcessLoop","Method Name":"onReceive","File Name":"DAGScheduler.scala","Line Number":3224},{"Declaring Class":"org.apache.spark.util.EventLoop$$anon$1","Method Name":"run","File Name":"EventLoop.scala","Line Number":49},{"Declaring Class":"org.apache.spark.scheduler.DAGScheduler","Method Name":"runJob","File Name":"DAGScheduler.scala","Line Number":1047},{"Declaring Class":"org.apache.spark.SparkContext","Method Name":"runJob","File Name":"SparkContext.scala","Line Number":2501},{"Declaring Class":"org.apache.spark.SparkContext","Method Name":"runJob","File Name":"SparkContext.scala","Line Number":2596},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$fold$1","File Name":"RDD.scala","Line Number":1203},{"Declaring Class":"org.apache.spark.rdd.RDDOperationScope$","Method Name":"withScope","File Name":"RDDOperationScope.scala","Line Number":152},{"Declaring Class":"org.apache.spark.rdd.RDDOperationScope$","Method Name":"withScope","File Name":"RDDOperationScope.scala","Line Number":113},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"withScope","File Name":"RDD.scala","Line Number":411},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"fold","File Name":"RDD.scala","Line Number":1197},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$treeAggregate$2","File Name":"RDD.scala","Line Number":1290},{"Declaring Class":"org.apache.spark.rdd.RDDOperationScope$","Method Name":"withScope","File Name":"RDDOperationScope.scala","Line Number":152},{"Declaring Class":"org.apache.spark.rdd.RDDOperationScope$","Method Name":"withScope","File Name":"RDDOperationScope.scala","Line Number":113},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"withScope","File Name":"RDD.scala","Line Number":411},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"treeAggregate","File Name":"RDD.scala","Line Number":1257},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"$anonfun$treeAggregate$1","File Name":"RDD.scala","Line Number":1243},{"Declaring Class":"org.apache.spark.rdd.RDDOperationScope$","Method Name":"withScope","File Name":"RDDOperationScope.scala","Line Number":152},{"Declaring Class":"org.apache.spark.rdd.RDDOperationScope$","Method Name":"withScope","File Name":"RDDOperationScope.scala","Line Number":113},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"withScope","File Name":"RDD.scala","Line Number":411},{"Declaring Class":"org.apache.spark.rdd.RDD","Method Name":"treeAggregate","File Name":"RDD.scala","Line Number":1243},{"Declaring Class":"org.apache.spark.sql.glue.util.SchemaUtils$","Method Name":"fromRDD","File Name":"SchemaUtils.scala","Line Number":78},{"Declaring Class":"com.amazonaws.services.glue.DynamicFrame","Method Name":"recomputeSchema","File Name":"DynamicFrame.scala","Line Number":297},{"Declaring Class":"com.amazonaws.services.glue.DynamicFrame","Method Name":"schema","File Name":"DynamicFrame.scala","Line Number":274},{"Declaring Class":"com.amazonaws.services.glue.DynamicFrame","Method Name":"toDF","File Name":"DynamicFrame.scala","Line Number":363},{"Declaring Class":"com.amazonaws.services.glue.dq.EvaluateDataQuality$","Method Name":"processRows","File Name":"EvaluateDataQuality.scala","Line Number":64},{"Declaring Class":"com.amazonaws.services.glue.dq.EvaluateDataQuality","Method Name":"processRows","File Name":"EvaluateDataQuality.scala","Line Number":-1},{"Declaring Class":"jdk.internal.reflect.NativeMethodAccessorImpl","Method Name":"invoke0","File Name":"NativeMethodAccessorImpl.java","Line Number":-2},{"Declaring Class":"jdk.internal.reflect.NativeMethodAccessorImpl","Method Name":"invoke","File Name":"NativeMethodAccessorImpl.java","Line Number":77},{"Declaring Class":"jdk.internal.reflect.DelegatingMethodAccessorImpl","Method Name":"invoke","File Name":"DelegatingMethodAccessorImpl.java","Line Number":43},{"Declaring Class":"java.lang.reflect.Method","Method Name":"invoke","File Name":"Method.java","Line Number":569},{"Declaring Class":"py4j.reflection.MethodInvoker","Method Name":"invoke","File Name":"MethodInvoker.java","Line Number":244},{"Declaring Class":"py4j.reflection.ReflectionEngine","Method Name":"invoke","File Name":"ReflectionEngine.java","Line Number":374},{"Declaring Class":"py4j.Gateway","Method Name":"invoke","File Name":"Gateway.java","Line Number":282},{"Declaring Class":"py4j.commands.AbstractCommand","Method Name":"invokeMethod","File Name":"AbstractCommand.java","Line Number":132},{"Declaring Class":"py4j.commands.CallCommand","Method Name":"execute","File Name":"CallCommand.java","Line Number":79},{"Declaring Class":"py4j.ClientServerConnection","Method Name":"waitForCommands","File Name":"ClientServerConnection.java","Line Number":182},{"Declaring Class":"py4j.ClientServerConnection","Method Name":"run","File Name":"ClientServerConnection.java","Line Number":106},{"Declaring Class":"java.lang.Thread","Method Name":"run","File Name":"Thread.java","Line Number":840}]}}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"TaskKilled","Kill Reason":"Stage cancelled: Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulator Updates":[{"ID":126,"Update":"7036","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"106","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"11776142","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"8493664","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"8582","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":8,"Index":4,"Attempt":0,"Partition ID":4,"Launch Time":1736633197635,"Executor ID":"8","Host":"172.39.70.41","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204725,"Failed":false,"Killed":true,"Accumulables":[]},"Task Executor Metrics":{"JVMHeapMemory":258494608,"JVMOffHeapMemory":144382520,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":976543,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":976543,"OffHeapUnifiedMemory":0,"DirectPoolMemory":16849176,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":22,"MinorGCTime":241,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":241},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":7036,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":106,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":11776142,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":8493664,"Records Read":8582},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"TaskKilled","Kill Reason":"Stage cancelled: Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulator Updates":[{"ID":126,"Update":"7034","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"98","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"46135574","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"25607458","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"20599","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":5,"Index":1,"Attempt":0,"Partition ID":1,"Launch Time":1736633197633,"Executor ID":"9","Host":"172.38.148.117","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204744,"Failed":false,"Killed":true,"Accumulables":[]},"Task Executor Metrics":{"JVMHeapMemory":408446720,"JVMOffHeapMemory":164808232,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":17782198,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":17782198,"OffHeapUnifiedMemory":0,"DirectPoolMemory":33923863,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":21,"MinorGCTime":282,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":282},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":7034,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":98,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":46135574,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":25607458,"Records Read":20599},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"TaskKilled","Kill Reason":"Stage cancelled: Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulator Updates":[{"ID":126,"Update":"271","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"5426714","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"1481585","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"776","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":44,"Index":5,"Attempt":2,"Partition ID":5,"Launch Time":1736633204455,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204748,"Failed":false,"Killed":true,"Accumulables":[]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":271,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":5426714,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":1481585,"Records Read":776},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"TaskKilled","Kill Reason":"Stage cancelled: Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulator Updates":[{"ID":126,"Update":"6990","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"100","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"54820054","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"40419936","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"25824","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":6,"Index":2,"Attempt":0,"Partition ID":2,"Launch Time":1736633197634,"Executor ID":"3","Host":"172.36.184.148","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204749,"Failed":false,"Killed":true,"Accumulables":[]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":6990,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":100,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":54820054,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":40419936,"Records Read":25824},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"TaskKilled","Kill Reason":"Stage cancelled: Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulator Updates":[{"ID":126,"Update":"6998","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"109","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"8780063","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"4887554","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"4729","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Partition ID":0,"Launch Time":1736633197623,"Executor ID":"7","Host":"172.34.194.64","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204751,"Failed":false,"Killed":true,"Accumulables":[]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":6998,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":109,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":8780063,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":4887554,"Records Read":4729},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"TaskKilled","Kill Reason":"Stage cancelled: Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulator Updates":[{"ID":126,"Update":"7072","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"111","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"12107185","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"6956858","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"7155","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":7,"Index":3,"Attempt":0,"Partition ID":3,"Launch Time":1736633197635,"Executor ID":"1","Host":"172.36.182.108","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204782,"Failed":false,"Killed":true,"Accumulables":[]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":7072,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":111,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":12107185,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":6956858,"Records Read":7155},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"TaskKilled","Kill Reason":"Stage cancelled: Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulator Updates":[{"ID":126,"Update":"7114","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"111","Internal":false,"Count Failed Values":true},{"ID":153,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":154,"Update":"15325025","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"7794690","Internal":false,"Count Failed Values":true},{"ID":156,"Update":"7444","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":12,"Index":8,"Attempt":0,"Partition ID":8,"Launch Time":1736633197640,"Executor ID":"1","Host":"172.36.182.108","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204823,"Failed":false,"Killed":true,"Accumulables":[]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":7114,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":111,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":15325025,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":7794690,"Records Read":7444},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ShuffleMapTask","Task End Reason":{"Reason":"TaskKilled","Kill Reason":"Stage cancelled: Job aborted due to stage failure: Task 10 in stage 3.0 failed 4 times, most recent failure: Lost task 10.3 in stage 3.0 (TID 43) (172.38.148.117 executor 9): com.amazonaws.services.glue.util.FatalException: Unable to parse file: MXvideos.csv\n\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNextFailSafe(JacksonReader.scala:94)\n\tat com.amazonaws.services.glue.readers.JacksonReader.hasNext(JacksonReader.scala:38)\n\tat com.amazonaws.services.glue.readers.CSVReader.hasNext(CSVReader.scala:185)\n\tat com.amazonaws.services.glue.hadoop.TapeHadoopRecordReaderSplittable.nextKeyValue(TapeHadoopRecordReaderSplittable.scala:95)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.$anonfun$hasNext$1(NewHadoopRDD.scala:264)\n\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n\tat org.apache.spark.util.FileAccessContext$.withContext(FileAccessContext.scala:41)\n\tat org.apache.spark.rdd.NewHadoopRDD$$anon$1.hasNext(NewHadoopRDD.scala:261)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:513)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:183)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.doWrite(ShuffleWriteProcessor.scala:45)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:69)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:104)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:54)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:174)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:152)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:632)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:96)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:635)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n\nDriver stacktrace:","Accumulator Updates":[{"ID":126,"Update":"3239","Internal":false,"Count Failed Values":true},{"ID":128,"Update":"0","Internal":false,"Count Failed Values":true},{"ID":129,"Update":"40","Internal":false,"Count Failed Values":true},{"ID":155,"Update":"16384","Internal":false,"Count Failed Values":true}]},"Task Info":{"Task ID":16,"Index":6,"Attempt":1,"Partition ID":6,"Launch Time":1736633201506,"Executor ID":"2","Host":"172.38.127.204","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1736633204907,"Failed":false,"Killed":true,"Accumulables":[]},"Task Executor Metrics":{"JVMHeapMemory":0,"JVMOffHeapMemory":0,"OnHeapExecutionMemory":0,"OffHeapExecutionMemory":0,"OnHeapStorageMemory":0,"OffHeapStorageMemory":0,"OnHeapUnifiedMemory":0,"OffHeapUnifiedMemory":0,"DirectPoolMemory":0,"MappedPoolMemory":0,"ProcessTreeJVMVMemory":0,"ProcessTreeJVMRSSMemory":0,"ProcessTreePythonVMemory":0,"ProcessTreePythonRSSMemory":0,"ProcessTreeOtherVMemory":0,"ProcessTreeOtherRSSMemory":0,"MinorGCCount":0,"MinorGCTime":0,"MajorGCCount":0,"MajorGCTime":0,"TotalGCTime":0},"Task Metrics":{"Executor Deserialize Time":0,"Executor Deserialize CPU Time":0,"Executor Run Time":3239,"Executor CPU Time":0,"Peak Execution Memory":0,"Result Size":0,"JVM GC Time":40,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Shuffle Read Metrics":{"Remote Blocks Fetched":0,"Local Blocks Fetched":0,"Fetch Wait Time":0,"Remote Bytes Read":0,"Remote Bytes Read To Disk":0,"Local Bytes Read":0,"Total Records Read":0,"Remote Requests Duration":0,"Push Based Shuffle":{"Corrupt Merged Block Chunks":0,"Merged Fetch Fallback Count":0,"Merged Remote Blocks Fetched":0,"Merged Local Blocks Fetched":0,"Merged Remote Chunks Fetched":0,"Merged Local Chunks Fetched":0,"Merged Remote Bytes Read":0,"Merged Local Bytes Read":0,"Merged Remote Requests Duration":0}},"Shuffle Write Metrics":{"Shuffle Bytes Written":0,"Shuffle Write Time":0,"Shuffle Records Written":0},"Input Metrics":{"Bytes Read":16384,"Records Read":0},"Output Metrics":{"Bytes Written":0,"Records Written":0},"Updated Blocks":[]}}
{"Event":"SparkListenerApplicationEnd","Timestamp":1736633205180}
